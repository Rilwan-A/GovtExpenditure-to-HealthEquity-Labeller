{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating Illustrations of the Comparisons between performance of different approaches to predictions on SPOT Dataset\n",
    "## We create two sets of analyses: 1) For predictions with the Public Health budget item 2) For predictions without the Public Health budget items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.metrics import precision_recall_fscore_support, accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define which experiments to analyse\n",
    "dir_expirements = './output/spot'\n",
    "\n",
    "# NOTE: Change this to decide which experiments to analyse\n",
    "# get names of folders in a directory that match a pattern\n",
    "experiment_names = sorted(glob.glob(dir_expirements+'/*/*'))\n",
    "experiment_names = [name for name in experiment_names if ('summary' not in name) and ('figures' not in name) ]\n",
    "experiment_names_WPH = [name for name in experiment_names if 'RPH' not in name] \n",
    "experiment_names_RPH = [name for name in experiment_names if 'RPH' in name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./output/spot/EleutherAI_gpt-neox-20b/_PSo_AGmv_POlmp_DId_RPH',\n",
       " './output/spot/EleutherAI_gpt-neox-20b/_PSo_K2_AGmv_POlmp_DId_RPH',\n",
       " './output/spot/EleutherAI_gpt-neox-20b/_PSpo_AGmv_POlmg_DId_RPH',\n",
       " './output/spot/EleutherAI_gpt-neox-20b/_PSpo_AGmv_POlmp_DId_RPH',\n",
       " './output/spot/EleutherAI_gpt-neox-20b/_PSpo_K2_AGmv_POlmg_DId_RPH',\n",
       " './output/spot/EleutherAI_gpt-neox-20b/_PSpo_K2_AGmv_POlmp_DId_RPH',\n",
       " './output/spot/EleutherAI_gpt-neox-20b/_PSyn_AGmv_POlmg_DId_RPH',\n",
       " './output/spot/EleutherAI_gpt-neox-20b/_PSyn_AGmv_POlmp_DId_RPH',\n",
       " './output/spot/EleutherAI_gpt-neox-20b/_PSyn_AGmv_POrb_DId_RPH',\n",
       " './output/spot/EleutherAI_gpt-neox-20b/_PSyn_K2_AGmv_POlmg_DId_RPH',\n",
       " './output/spot/EleutherAI_gpt-neox-20b/_PSyn_K2_AGmv_POlmp_DId_RPH',\n",
       " './output/spot/EleutherAI_gpt-neox-20b/_PSyn_K2_AGmv_POrb_DId_RPH',\n",
       " './output/spot/gpt35turbo/directly_RPH',\n",
       " './output/spot/gpt35turbo/indirectly_RPH',\n",
       " './output/spot/gpt35turbo/neutral_RPH']"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experiment_names_RPH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the column name for the label and column name for the prediction\n",
    "target_column = 'label'\n",
    "prediction_column = 'preds_aggregate'\n",
    "\n",
    "## Testing Loading of predictions for one experiment\n",
    "df_preds = pd.read_csv(f'{experiment_names_WPH[0]}/predictions.csv', keep_default_na=False)\n",
    "targets = df_preds[target_column].tolist()\n",
    "preds = df_preds[prediction_column].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "279"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len( df_preds['indicator'].unique() )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['budget_item', 'id', 'indicator', 'type', 'label', 'preds_aggregate',\n",
       "       'preds_ensemble_parsed', 'preds_ensemble', 'preds_prompts'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_preds.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Silence UndefinedMetricWarning\n",
    "import warnings\n",
    "from sklearn.exceptions import UndefinedMetricWarning\n",
    "warnings.filterwarnings(\"ignore\", category=UndefinedMetricWarning)\n",
    "\n",
    "def calc_metrics_for_experiment_group(experiment_names, budget_item=None ):\n",
    "    li_exp_metrics = []\n",
    "\n",
    "    # For each experiment name calculate the metrics: precision, recall, f1, accuracy\n",
    "    for exp_name in experiment_names:\n",
    "\n",
    "        # Get experiment predictions\n",
    "        df_preds = pd.read_csv(f'{exp_name}/predictions.csv', keep_default_na=False)\n",
    "\n",
    "        if budget_item is not None:\n",
    "            df_preds = df_preds[df_preds['budget_item'] == budget_item]\n",
    "        \n",
    "        targets = df_preds[target_column].tolist()\n",
    "        preds = df_preds[prediction_column].tolist()\n",
    "\n",
    "        # formatting preds\n",
    "        preds = [ p.strip('. ') for p in preds ]\n",
    "        \n",
    "        # Calculate metrics\n",
    "        (prec_yes, prec_no), (recall_yes, recall_no), (f1_yes, f1_no), _ = precision_recall_fscore_support(targets, preds, labels=['Yes','No'], average=None)\n",
    "        prec = (prec_yes + prec_no  ) /2 \n",
    "        recall = (recall_yes + recall_no ) /2\n",
    "        f1 = (f1_yes + f1_no ) /2\n",
    "\n",
    "        \n",
    "        acc = accuracy_score(targets, preds)\n",
    "\n",
    "        # Store metrics\n",
    "        li_exp_metrics.append( \n",
    "            {'exp_name':exp_name, \n",
    "                'precision_yes':prec_yes, 'precision':prec, 'precision_no':prec_no,\n",
    "                'recall_yes':recall_yes, 'recall':recall, 'recall_no':recall_no,\n",
    "                'f1_yes':f1_yes, 'f1_no':f1_no, 'f1':f1, \n",
    "                'accuracy':acc} )\n",
    "\n",
    "    df_metrics = pd.DataFrame.from_records(li_exp_metrics)\n",
    "    df_metrics = df_metrics.set_index('exp_name')\n",
    "    df_metrics = df_metrics.sort_values('accuracy', ascending=False)\n",
    "\n",
    "    return df_metrics\n",
    "\n",
    "df_metrics_WPH = calc_metrics_for_experiment_group(experiment_names_WPH)\n",
    "df_metrics_RPH = calc_metrics_for_experiment_group(experiment_names_RPH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision_yes</th>\n",
       "      <th>precision</th>\n",
       "      <th>precision_no</th>\n",
       "      <th>recall_yes</th>\n",
       "      <th>recall</th>\n",
       "      <th>recall_no</th>\n",
       "      <th>f1_yes</th>\n",
       "      <th>f1_no</th>\n",
       "      <th>f1</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>exp_name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>./output/spot/gpt35turbo/directly_RPH</th>\n",
       "      <td>0.793103</td>\n",
       "      <td>0.795029</td>\n",
       "      <td>0.796954</td>\n",
       "      <td>0.781553</td>\n",
       "      <td>0.771845</td>\n",
       "      <td>0.762136</td>\n",
       "      <td>0.787286</td>\n",
       "      <td>0.779156</td>\n",
       "      <td>0.783221</td>\n",
       "      <td>0.771845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>./output/spot/gpt35turbo/neutral_RPH</th>\n",
       "      <td>0.721774</td>\n",
       "      <td>0.788519</td>\n",
       "      <td>0.855263</td>\n",
       "      <td>0.868932</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.631068</td>\n",
       "      <td>0.788546</td>\n",
       "      <td>0.726257</td>\n",
       "      <td>0.757402</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>./output/spot/gpt35turbo/indirectly_RPH</th>\n",
       "      <td>0.659649</td>\n",
       "      <td>0.761276</td>\n",
       "      <td>0.862903</td>\n",
       "      <td>0.912621</td>\n",
       "      <td>0.716019</td>\n",
       "      <td>0.519417</td>\n",
       "      <td>0.765784</td>\n",
       "      <td>0.648485</td>\n",
       "      <td>0.707134</td>\n",
       "      <td>0.716019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>./output/spot/EleutherAI_gpt-neox-20b/_PSyn_K2_AGmv_POrb_DId_RPH</th>\n",
       "      <td>0.521531</td>\n",
       "      <td>0.521849</td>\n",
       "      <td>0.522167</td>\n",
       "      <td>0.529126</td>\n",
       "      <td>0.521845</td>\n",
       "      <td>0.514563</td>\n",
       "      <td>0.525301</td>\n",
       "      <td>0.518337</td>\n",
       "      <td>0.521819</td>\n",
       "      <td>0.521845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>./output/spot/EleutherAI_gpt-neox-20b/_PSyn_K2_AGmv_POlmg_DId_RPH</th>\n",
       "      <td>0.511962</td>\n",
       "      <td>0.512138</td>\n",
       "      <td>0.512315</td>\n",
       "      <td>0.519417</td>\n",
       "      <td>0.512136</td>\n",
       "      <td>0.504854</td>\n",
       "      <td>0.515663</td>\n",
       "      <td>0.508557</td>\n",
       "      <td>0.512110</td>\n",
       "      <td>0.512136</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    precision_yes  precision  \\\n",
       "exp_name                                                                       \n",
       "./output/spot/gpt35turbo/directly_RPH                    0.793103   0.795029   \n",
       "./output/spot/gpt35turbo/neutral_RPH                     0.721774   0.788519   \n",
       "./output/spot/gpt35turbo/indirectly_RPH                  0.659649   0.761276   \n",
       "./output/spot/EleutherAI_gpt-neox-20b/_PSyn_K2_...       0.521531   0.521849   \n",
       "./output/spot/EleutherAI_gpt-neox-20b/_PSyn_K2_...       0.511962   0.512138   \n",
       "\n",
       "                                                    precision_no  recall_yes  \\\n",
       "exp_name                                                                       \n",
       "./output/spot/gpt35turbo/directly_RPH                   0.796954    0.781553   \n",
       "./output/spot/gpt35turbo/neutral_RPH                    0.855263    0.868932   \n",
       "./output/spot/gpt35turbo/indirectly_RPH                 0.862903    0.912621   \n",
       "./output/spot/EleutherAI_gpt-neox-20b/_PSyn_K2_...      0.522167    0.529126   \n",
       "./output/spot/EleutherAI_gpt-neox-20b/_PSyn_K2_...      0.512315    0.519417   \n",
       "\n",
       "                                                      recall  recall_no  \\\n",
       "exp_name                                                                  \n",
       "./output/spot/gpt35turbo/directly_RPH               0.771845   0.762136   \n",
       "./output/spot/gpt35turbo/neutral_RPH                0.750000   0.631068   \n",
       "./output/spot/gpt35turbo/indirectly_RPH             0.716019   0.519417   \n",
       "./output/spot/EleutherAI_gpt-neox-20b/_PSyn_K2_...  0.521845   0.514563   \n",
       "./output/spot/EleutherAI_gpt-neox-20b/_PSyn_K2_...  0.512136   0.504854   \n",
       "\n",
       "                                                      f1_yes     f1_no  \\\n",
       "exp_name                                                                 \n",
       "./output/spot/gpt35turbo/directly_RPH               0.787286  0.779156   \n",
       "./output/spot/gpt35turbo/neutral_RPH                0.788546  0.726257   \n",
       "./output/spot/gpt35turbo/indirectly_RPH             0.765784  0.648485   \n",
       "./output/spot/EleutherAI_gpt-neox-20b/_PSyn_K2_...  0.525301  0.518337   \n",
       "./output/spot/EleutherAI_gpt-neox-20b/_PSyn_K2_...  0.515663  0.508557   \n",
       "\n",
       "                                                          f1  accuracy  \n",
       "exp_name                                                                \n",
       "./output/spot/gpt35turbo/directly_RPH               0.783221  0.771845  \n",
       "./output/spot/gpt35turbo/neutral_RPH                0.757402  0.750000  \n",
       "./output/spot/gpt35turbo/indirectly_RPH             0.707134  0.716019  \n",
       "./output/spot/EleutherAI_gpt-neox-20b/_PSyn_K2_...  0.521819  0.521845  \n",
       "./output/spot/EleutherAI_gpt-neox-20b/_PSyn_K2_...  0.512110  0.512136  "
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_metrics_RPH.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving to file\n",
    "def saving_to_file(dir_expirements, df_metrics, exp_name):\n",
    "    os.makedirs(os.path.join(dir_expirements, 'summary'), exist_ok=True)\n",
    "    df_metrics.to_csv( os.path.join(dir_expirements, 'summary', f'{exp_name}.csv') )\n",
    "\n",
    "saving_to_file(dir_expirements, df_metrics_WPH, 'WPH')\n",
    "saving_to_file(dir_expirements, df_metrics_RPH, 'RPH')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileExistsError",
     "evalue": "[Errno 17] File exists: './output/spot/figures'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileExistsError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[75], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m metric_names \u001b[39m=\u001b[39m [ \u001b[39m'\u001b[39m\u001b[39maccuracy\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39mf1\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mprecision\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mrecall\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mf1_yes\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mprecision_yes\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mrecall_yes\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mf1_no\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mprecision_no\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mrecall_no\u001b[39m\u001b[39m'\u001b[39m ]\n\u001b[1;32m      3\u001b[0m metric_names_fmt \u001b[39m=\u001b[39m [\u001b[39m'\u001b[39m\u001b[39mAccuracy\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mF1 Score\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mRecall\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mF1 Score Yes\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mPrecision Yes\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mRecall - Yes\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mF1 Score - No\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mPrecision - No\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mRecall - No\u001b[39m\u001b[39m'\u001b[39m ]\n\u001b[0;32m----> 5\u001b[0m os\u001b[39m.\u001b[39;49mmakedirs( os\u001b[39m.\u001b[39;49mpath\u001b[39m.\u001b[39;49mjoin(dir_expirements, \u001b[39m'\u001b[39;49m\u001b[39mfigures\u001b[39;49m\u001b[39m'\u001b[39;49m) )\n\u001b[1;32m      6\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mimage_top_n_metrics\u001b[39m(df_metrics, dir_expirements, metric_names, metric_names_fmt\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, top_n\u001b[39m=\u001b[39m\u001b[39m5\u001b[39m, RPH\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m):\n\u001b[1;32m      8\u001b[0m     \u001b[39mif\u001b[39;00m metric_names_fmt \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/alanturing/lib/python3.10/os.py:225\u001b[0m, in \u001b[0;36mmakedirs\u001b[0;34m(name, mode, exist_ok)\u001b[0m\n\u001b[1;32m    223\u001b[0m         \u001b[39mreturn\u001b[39;00m\n\u001b[1;32m    224\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 225\u001b[0m     mkdir(name, mode)\n\u001b[1;32m    226\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mOSError\u001b[39;00m:\n\u001b[1;32m    227\u001b[0m     \u001b[39m# Cannot rely on checking for EEXIST, since the operating system\u001b[39;00m\n\u001b[1;32m    228\u001b[0m     \u001b[39m# could give priority to other errors like EACCES or EROFS\u001b[39;00m\n\u001b[1;32m    229\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m exist_ok \u001b[39mor\u001b[39;00m \u001b[39mnot\u001b[39;00m path\u001b[39m.\u001b[39misdir(name):\n",
      "\u001b[0;31mFileExistsError\u001b[0m: [Errno 17] File exists: './output/spot/figures'"
     ]
    }
   ],
   "source": [
    "# Comparing the Performance with split by label\n",
    "metric_names = [ 'accuracy','f1', 'precision', 'recall', 'f1_yes', 'precision_yes', 'recall_yes', 'f1_no', 'precision_no', 'recall_no' ]\n",
    "metric_names_fmt = ['Accuracy', 'F1 Score', 'Recall', 'F1 Score Yes', 'Precision Yes', 'Recall - Yes', 'F1 Score - No', 'Precision - No', 'Recall - No' ]\n",
    "\n",
    "os.makedirs( os.path.join(dir_expirements, 'figures') )\n",
    "def image_top_n_metrics(df_metrics, dir_expirements, metric_names, metric_names_fmt=None, top_n=5, RPH=False):\n",
    "\n",
    "    if metric_names_fmt is None:\n",
    "        metric_names_fmt = metric_names\n",
    "        \n",
    "    df_metrics_top = df_metrics.sort_values('accuracy', ascending=False).head( top_n )\n",
    "\n",
    "    x_axis_labels = {\n",
    "        0: '1st',\n",
    "        1: '2nd',\n",
    "        2: '3rd',\n",
    "        3: '4th',\n",
    "        4: '5th',\n",
    "    }\n",
    "\n",
    "    for metric_name, metric_name_fmt in zip(metric_names, metric_names_fmt):\n",
    "        values = df_metrics_top[metric_name]\n",
    "        \n",
    "        fig, ax = plt.subplots()\n",
    "        ax.bar(range(len(values)), values)\n",
    "        ax.set_xticks(range(len(values)))\n",
    "        ax.set_xticklabels([x_axis_labels[val] for val in values])\n",
    "        ax.set_title(metric_name)\n",
    "        ax.set_xlabel('Values')\n",
    "        ax.set_ylabel(metric_name)\n",
    "        for i, v in enumerate(values):\n",
    "            ax.text(i, v, f\"{v:.2f}\", ha='center')\n",
    "        \n",
    "        plt.savefig( os.path.join(dir_expirements, 'figures', f'{metric_name_fmt}_top_{top_n}'+ 'RPH'*RPH +'.png' ) )\n",
    "        \n",
    "        plt.show()\n",
    "\n",
    "# image_top_n_metrics(df_metrics_WPH, dir_expirements, metric_names, metric_names_fmt, top_n=5, RPH=False)\n",
    "image_top_n_metrics(df_metrics_RPH, dir_expirements, metric_names, metric_names_fmt, top_n=5, RPH=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating Performance metric with a analyses performed on data split by budget item value\n",
    "\n",
    "WPH_budget_items = ['Public Health', 'Child Health', 'Healthcare', 'Mental Health',\n",
    "       'Health Protection', 'Highways', 'Social Care - Adults',\n",
    "       'Social Care - Child', 'Health Improvement', 'Education',\n",
    "       'Drugs and Alcohol', 'Housing', 'Sexual Health', 'Tobacco Control',\n",
    "       'Planning', 'Env & Reg']\n",
    "\n",
    "RPH_budget_items = ['Child Health', 'Healthcare', 'Mental Health',\n",
    "       'Health Protection', 'Highways', 'Social Care - Adults',\n",
    "       'Social Care - Child', 'Health Improvement', 'Education',\n",
    "       'Drugs and Alcohol', 'Housing', 'Sexual Health', 'Tobacco Control',\n",
    "       'Planning', 'Env & Reg']\n",
    "\n",
    "dict_budgetitem_metrics_WPH = {}\n",
    "dict_budgetitem_metrics_RPH = {}\n",
    "\n",
    "#Creating Metrics for each budget item\n",
    "for budget_item in WPH_budget_items:\n",
    "       dict_budgetitem_metrics_WPH[budget_item] = calc_metrics_for_experiment_group(experiment_names_WPH, budget_item=budget_item)\n",
    "\n",
    "for budget_item in RPH_budget_items:\n",
    "       dict_budgetitem_metrics_RPH[budget_item] = calc_metrics_for_experiment_group(experiment_names_RPH, budget_item=budget_item)\n",
    "\n",
    "# Saving each metric table to file\n",
    "for budget_item, metrics in dict_budgetitem_metrics_WPH.items():\n",
    "       saving_to_file(dir_expirements, metrics, f'WPH_{budget_item}')\n",
    "\n",
    "for budget_item, metrics in dict_budgetitem_metrics_RPH.items():\n",
    "       saving_to_file(dir_expirements, metrics, f'RPH_{budget_item}')\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "alanturing",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "cc50b8d0f7e8d8fb88331066a22b4d3e98f2c46ac896a3cf7dc663ff0af4e185"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
