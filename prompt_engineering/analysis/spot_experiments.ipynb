{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyses for the SPOT Alignment Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.metrics import precision_recall_fscore_support, accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import re\n",
    "import yaml\n",
    "dir_expirements = '../output/spot/exp_runs'\n",
    "dir_figures = '../output/spot/figures'\n",
    "dir_tables = '../output/spot/tables'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Factors to Compare Models on\n",
    "- All models and variants comparison\n",
    "- Comparing effect of 'parse_sytle' and 'prompt_style' : ['yes_no','open','categorise','cot_categorise']  and ['rules','categories_rules', 'categories_perplexity']\n",
    "- Effect Type : ['indirectly','directly','arbitrary']\n",
    "- 'model parameter count' : judged by model name\n",
    "- finetuned : [True, False]\n",
    "- unbias predictions\n",
    "\n",
    "#### TODOs Diagrams/Tables to Produce\n",
    "- 1) Tables: Accuracy, F1, Precision and Recall (of non-finetuned and finetuned models with varied parse_style_prompt_style but effect_type fixed to 'directly')\n",
    "- 2) [Probabilistic predictions]: AUC-ROC, Brier Score (of non-finetuned and finetuned models with varied parse_style_prompt_style but effect_type fixed to 'indirectly' )\n",
    "- 3) Performance cross sectioned by the budget item category\n",
    "- 4) Performance cross sectioned by the budget item pre and post finetuning - In relation to dataset distribution e.g. more articles on 'health' than 'education' so we expect better performance increase on 'health' than 'education'. And the possible effects on downstream model from this e.g. are effects with more academic research better modelled. Or if there are correllated factors, we will essentially learn better studied factors more\n",
    "- 5) Performance change in top performing models when effect tyle is rotated between effect types\n",
    "- 6) Table showing Performance change w/ and w/o using -unbiase predictions flag for top models\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.metrics import precision_recall_fscore_support, accuracy_score\n",
    "# import roc curve printing, roc_auc_score, brier_score_loss\n",
    "from sklearn.metrics import roc_curve, auc, roc_auc_score, brier_score_loss\n",
    "import warnings\n",
    "from sklearn.exceptions import UndefinedMetricWarning\n",
    "warnings.filterwarnings(\"ignore\", category=UndefinedMetricWarning)\n",
    "import matplotlib.pyplot as plt\n",
    "import operator\n",
    "import copy\n",
    "import numpy as np\n",
    "\n",
    "def load_data() -> list[dict]:\n",
    "    \"\"\"Experiments are stored as a csv file in the following format: budget_item,indicator,label,pred_aggregated,prompts,predictions,discourse\n",
    "        Each experiment also contains a config file\n",
    "\n",
    "        Returns a list of dictionaries, where \n",
    "\n",
    "        Input format of csv file containing predictions: budget_item,indicator,label,pred_aggregated,prompts,predictions,discourse\n",
    "       \"\"\"\n",
    "    \n",
    "    experiment_paths = sorted(glob.glob(dir_expirements+'/*'))\n",
    "    li_exp = []\n",
    "    for path in experiment_paths:\n",
    "        path_config = os.path.join(path,'config.yaml')\n",
    "        path_results = os.path.join(path,'predictions_b2i.csv')\n",
    "\n",
    "        # Load config file\n",
    "        with open(path_config) as f:\n",
    "            config   =  yaml.safe_load(f)\n",
    "              \n",
    "        # Load results file\n",
    "        df = pd.read_csv(path_results)\n",
    "\n",
    "        li_exp.append( {'config':config, 'results':df} )\n",
    "    \n",
    "    return li_exp\n",
    "\n",
    "def filter_exp( li_exp, **filter_kwargs ) -> list[dict]:\n",
    "\n",
    "    li_exp_filtered = []\n",
    "\n",
    "    # first filter logic based on checking if any item in  the filter_kwarg is a substring of the config value\n",
    "    for exp in li_exp:\n",
    "        if 'llm_names' in filter_kwargs:\n",
    "            if any( llm_name in exp['config']['llm_name'].lower() for llm_name in filter_kwargs['llm_names'] ):\n",
    "                li_exp_filtered.append(exp)\n",
    "        else:\n",
    "            li_exp_filtered.append(exp)\n",
    "    \n",
    "    filter_kwargs.pop('llm_names', None)\n",
    "\n",
    "    # second filter logic based on checking if any item in list is in the config    \n",
    "    for idx in range(len(li_exp_filtered)-1, -1, -1):\n",
    "        exp = li_exp_filtered[idx]\n",
    "        if any( ( (exp['config'].get(filter_name) not in filter_values) for filter_name, filter_values in filter_kwargs.items() ) ):\n",
    "            # li_exp_filtered.append(exp)\n",
    "            li_exp_filtered.pop(idx)\n",
    "\n",
    "    return li_exp_filtered\n",
    "\n",
    "def calc_eval_metrics( li_exp, metrics:list = ['accuracy','precision','recall','f1','auc_roc','brier_score'], breakdown_by_budgetitem:bool=False, average_type=None ) -> dict:\n",
    "    \"\"\"\n",
    "        kwargs must be: keys,values = config argument, list of values to filter on\n",
    "\n",
    "        Filters experiments based on kwargs, then calculates metrics for each experiment\n",
    "    \"\"\"\n",
    "    \n",
    "    li_exp = copy.deepcopy(li_exp)\n",
    "\n",
    "    # Calculate metrics for each experiment\n",
    "    tgt_col = 'related'\n",
    "    pred_col_dict = 'pred_aggregated'\n",
    "    pred_col_label = 'pred_label' # For deterministic evaluation\n",
    "    # pred_col_prob = 'pred_prob'\n",
    "    \n",
    "    ## Making pred_label column\n",
    "    for exp in li_exp:\n",
    "\n",
    "        exp['results'][pred_col_label] = exp['results'][pred_col_dict].apply(lambda dict_: max(eval(dict_).items(), key=operator.itemgetter(1))[0])\n",
    "    \n",
    "    if 'auc_roc' in metrics or 'brier_score' in metrics or 'calibration_error' in metrics:\n",
    "        # Making pred_prob column e.g. Prob of predicting Yes\n",
    "        for exp in li_exp:\n",
    "            #note: the logic in the below line may be  a bit wrong, since it extracts the pred_col_prob of highest value, instead of the pred_col_prob for the label 'Yes' or 'No'\n",
    "            # exp['results'][pred_col_prob] = exp['results'][pred_col_dict].apply(lambda dict_: max(eval(dict_).items(), key=operator.itemgetter(1))[1])\n",
    "\n",
    "            exp['results']['pred_yes_prob'] = exp['results'][pred_col_dict].apply(lambda dict_: eval(dict_)['Yes'])\n",
    "            exp['results']['pred_no_prob'] = exp['results'][pred_col_dict].apply(lambda dict_: eval(dict_)['No'])\n",
    "\n",
    "            exp['results'][tgt_col+'_yes_prob'] = exp['results'][tgt_col].map(lambda x: 1.0 if x=='Yes' else 0.0)\n",
    "            exp['results'][tgt_col+'no_prob'] = exp['results'][tgt_col].map(lambda x: 1.0 if x=='No' else 0.0)          \n",
    "\n",
    "\n",
    "    if breakdown_by_budgetitem is False:\n",
    "        ## Accuracy\n",
    "        if 'accuracy' in metrics:\n",
    "            for exp in li_exp:\n",
    "                # Calculate accuracy\n",
    "                accuracy = accuracy_score(exp['results'][tgt_col], exp['results'][pred_col_label])\n",
    "                if 'metrics' in exp:\n",
    "                    exp['metrics'].update({'accuracy':accuracy})\n",
    "                else:\n",
    "                    exp['metrics'] = {'accuracy':accuracy}\n",
    "            \n",
    "        ## Precision, recall, f1\n",
    "        fpr_metrics = [metric for metric in metrics if metric in ['precision','recall','f1']]\n",
    "        if len(fpr_metrics) > 0:\n",
    "            for exp in li_exp:\n",
    "                # Calculate li_exp, recall, f1\n",
    "                precision, recall, f1, support = precision_recall_fscore_support(exp['results'][tgt_col],\n",
    "                                                                        exp['results'][pred_col_label],\n",
    "                                                                        labels=['Yes'] if average_type != 'binary' else ['Yes'],\n",
    "                                                                        #    average = None,\n",
    "                                                                            pos_label = 'Yes' if average_type == 'binary' else 1,\n",
    "                                                                            average=average_type,\n",
    "                                                                            #  average='micro'\n",
    "                                                                            zero_division=np.nan\n",
    "                                                                            )\n",
    "                \n",
    "                _ = {k:v for k,v in zip(['f1', 'precision','recall'], [f1, precision, recall]) if k in fpr_metrics}\n",
    "                # _['support'] = support\n",
    "                if 'metrics' in exp:\n",
    "                    exp['metrics'].update(_)\n",
    "                else:\n",
    "                    exp['metrics'] = _\n",
    "        \n",
    "        ## ROC_AUC\n",
    "        if 'roc_auc' in metrics:\n",
    "            for exp in li_exp:\n",
    "                # Calculate roc_auc\n",
    "                roc_auc = roc_auc_score(exp['results'][tgt_col+'_yes_prob'], exp['results']['pred_yes_prob'] )\n",
    "                if 'metrics' in exp:\n",
    "                    exp['metrics'].update({'roc_auc':roc_auc})\n",
    "                else:\n",
    "                    exp['metrics'] = {'roc_auc':roc_auc}\n",
    "        \n",
    "\n",
    "        \n",
    "        if 'calibration_error' in metrics:\n",
    "            for exp in li_exp:\n",
    "                # Calculate calibration_error\n",
    "                \n",
    "                calibration_error = np.mean(np.abs( exp['results'][tgt_col+'_yes_prob'] -  exp['results']['pred_yes_prob'] ) )\n",
    "                \n",
    "                if 'metrics' in exp:\n",
    "                    exp['metrics'].update({'calibration_error':calibration_error})\n",
    "                else:\n",
    "                    exp['metrics'] = {'calibration_error':calibration_error}\n",
    "    \n",
    "    else:\n",
    "        raise NotImplementedError('breakdown_by_budgetitem=True not implemented yet')\n",
    "        for exp in li_exp:\n",
    "            exp['metrics'] = {}\n",
    "            for budget_item in exp['results']['budget_item'].unique():\n",
    "                df = exp['results'][exp['results']['budget_item']==budget_item]\n",
    "                ## Accuracy\n",
    "                if 'accuracy' in metrics:\n",
    "                    # Calculate accuracy\n",
    "                    accuracy = accuracy_score(df[tgt_col], df[pred_col_label])\n",
    "                    exp['metrics'].update({f'accuracy_{budget_item}':accuracy})\n",
    "                \n",
    "                ## Precision, recall, f1\n",
    "                fpr_metrics = [metric for metric in metrics if metric in ['precision','recall','f1']]\n",
    "                if len(fpr_metrics) > 0:\n",
    "                    # Calculate li_exp, recall, f1\n",
    "                    precision, recall, f1, support = precision_recall_fscore_support(df[tgt_col],\n",
    "                                                                            df[pred_col_label],\n",
    "                                                                            labels=['Yes'] if average_type != 'binary' else None,\n",
    "                                                                            pos_label = 'Yes' if average_type == 'binary' else 1,\n",
    "                                                                                average=average_type,\n",
    "                                                                                zero_division=np.nan\n",
    "                                                                                )\n",
    "                    \n",
    "                    _ = {k:v for k,v in zip(['f1', 'precision','recall'], [f1, precision, recall]) if k in fpr_metrics}\n",
    "                    # _['support'] = support\n",
    "                    exp['metrics'].update({f'{k}_{budget_item}':v for k,v in _.items()})\n",
    "            \n",
    "                ## ROC_AUC\n",
    "                if 'roc_auc' in metrics:\n",
    "                    # Calculate roc_auc\n",
    "                    roc_auc = roc_auc_score(df[tgt_col], df[pred_col_prob], labels=['Yes','No'])\n",
    "                    exp['metrics'].update({f'roc_auc_{budget_item}':roc_auc})\n",
    "                \n",
    "                ## Brier Score\n",
    "                if 'brier_score' in metrics:\n",
    "                    # Calculate brier_score\n",
    "                    brier_score = brier_score_loss(df[tgt_col], df[pred_col_prob], pos_label='Yes')\n",
    "                    exp['metrics'].update({f'brier_score_{budget_item}':brier_score})\n",
    "\n",
    "                if 'calibration_error' in metrics:\n",
    "                    # Calculate calibration_error\n",
    "                    calibration_error = np.abs(df[tgt_col] - df[pred_col_prob])                    \n",
    "                    exp['metrics'].update({'calibration_error':calibration_error})\n",
    "\n",
    "    return li_exp\n",
    "\n",
    "def convert_li_exp_to_df(li_exp: list) -> pd.DataFrame:\n",
    "    \"\"\"Converts list of experiments to a dataframe\"\"\"\n",
    "    li_exp_metrics = []\n",
    "    for exp in li_exp:\n",
    "        \n",
    "        exp_metrics = exp['metrics']\n",
    "        \n",
    "        llm_name = exp['config']['llm_name']\n",
    "        edge_value = exp['config']['edge_value']\n",
    "        effect_type = exp['config']['effect_type']\n",
    "        finetuned = exp['config']['finetuned']\n",
    "        parse_style = exp['config']['parse_style']\n",
    "        prompt_style = exp['config']['prompt_style']\n",
    "        uc = exp['config'].get('unbias_categorisations', False)\n",
    "        exp_metrics.update({'llm_name':llm_name,\n",
    "                            'edge_value':edge_value,\n",
    "                            'effect_type':effect_type,\n",
    "                            'finetuned':finetuned,\n",
    "                            'parse_style':parse_style,\n",
    "                            'prompt_style':prompt_style,\n",
    "                            'uc':uc\n",
    "                            })\n",
    "        \n",
    "        li_exp_metrics.append(exp_metrics)\n",
    "\n",
    "    df = pd.DataFrame(li_exp_metrics)\n",
    "\n",
    "    # Put the llm_name column first\n",
    "    cols = df.columns.tolist()\n",
    "    cols.insert(0, cols.pop(cols.index('llm_name')))\n",
    "    df = df.reindex(columns=cols)\n",
    "\n",
    "    return df\n",
    "\n",
    "def create_diagrams_from_dataframe(df_exp: pd.DataFrame,\n",
    "                                   columns_to_create_diagrams_for=['accuracy','roc_auc','brier_score','precision','recall','f1'],\n",
    "                                   save_dir='./prompt_engineering/analysis/spot_output',\n",
    "                                   exp_name='CompareAll') -> dict:\n",
    "    \n",
    "    # Create directory if it doesn't exist\n",
    "    save_dir = os.path.join(save_dir, exp_name)\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    \n",
    "    # Dictionary to store the paths of the saved diagrams\n",
    "    saved_diagrams = {}\n",
    "    \n",
    "    # Iterate over each column to create a diagram\n",
    "    for column in columns_to_create_diagrams_for:\n",
    "        if column in df_exp.columns:\n",
    "            plt.figure(figsize=(10, 6))\n",
    "            df_exp[column].hist(bins=20)\n",
    "            plt.title(f'Histogram of {column}')\n",
    "            plt.xlabel(column)\n",
    "            plt.ylabel('Frequency')\n",
    "            \n",
    "            # Save the diagram\n",
    "            file_path = os.path.join(save_dir, f'{column}_histogram.png')\n",
    "            plt.savefig(file_path)\n",
    "            \n",
    "            # Store the path in the dictionary\n",
    "            saved_diagrams[column] = file_path\n",
    "            \n",
    "            # Close the plot to free up memory\n",
    "            plt.close()\n",
    "            \n",
    "    return saved_diagrams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparing the results of the spot experiments\n",
    "li_all_experiments = load_data( )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0) Determining the best model for each parameter size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>llm_name</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f1</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>roc_auc</th>\n",
       "      <th>calibration_error</th>\n",
       "      <th>edge_value</th>\n",
       "      <th>effect_type</th>\n",
       "      <th>finetuned</th>\n",
       "      <th>parse_style</th>\n",
       "      <th>prompt_style</th>\n",
       "      <th>uc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gpt-3.5-turbo</td>\n",
       "      <td>0.815534</td>\n",
       "      <td>0.829932</td>\n",
       "      <td>0.778723</td>\n",
       "      <td>0.888350</td>\n",
       "      <td>0.817961</td>\n",
       "      <td>0.182039</td>\n",
       "      <td>binary_weight</td>\n",
       "      <td>directly</td>\n",
       "      <td>False</td>\n",
       "      <td>categories_rules</td>\n",
       "      <td>open</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gpt-3.5-turbo</td>\n",
       "      <td>0.764563</td>\n",
       "      <td>0.794760</td>\n",
       "      <td>0.722222</td>\n",
       "      <td>0.883495</td>\n",
       "      <td>0.771845</td>\n",
       "      <td>0.228155</td>\n",
       "      <td>binary_weight</td>\n",
       "      <td>directly</td>\n",
       "      <td>False</td>\n",
       "      <td>rules</td>\n",
       "      <td>yes_no</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        llm_name  accuracy        f1  precision    recall   roc_auc  \\\n",
       "0  gpt-3.5-turbo  0.815534  0.829932   0.778723  0.888350  0.817961   \n",
       "1  gpt-3.5-turbo  0.764563  0.794760   0.722222  0.883495  0.771845   \n",
       "\n",
       "   calibration_error     edge_value effect_type  finetuned       parse_style  \\\n",
       "0           0.182039  binary_weight    directly      False  categories_rules   \n",
       "1           0.228155  binary_weight    directly      False             rules   \n",
       "\n",
       "  prompt_style    uc  \n",
       "0         open  None  \n",
       "1       yes_no  None  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Best gpt model\n",
    "li_exps_filtgpt = filter_exp(li_all_experiments, llm_names=['gpt'] )\n",
    "li_exps_filtgpt_w_res = calc_eval_metrics(li_exps_filtgpt, metrics=['accuracy','precision','recall','f1','calibration_error','roc_auc'], average_type='macro' )\n",
    "df_exps_filtgpt = convert_li_exp_to_df(li_exps_filtgpt_w_res)\n",
    "# Sort by accuracy\n",
    "df_exps_filtgpt.sort_values(by=['accuracy'], ascending=False, inplace=True)\n",
    "display(df_exps_filtgpt.head(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>llm_name</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f1</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>calibration_error</th>\n",
       "      <th>edge_value</th>\n",
       "      <th>effect_type</th>\n",
       "      <th>finetuned</th>\n",
       "      <th>parse_style</th>\n",
       "      <th>prompt_style</th>\n",
       "      <th>uc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>stabilityai/StableBeluga-7B</td>\n",
       "      <td>0.697</td>\n",
       "      <td>0.703</td>\n",
       "      <td>0.687</td>\n",
       "      <td>0.720</td>\n",
       "      <td>0.396</td>\n",
       "      <td>distribution</td>\n",
       "      <td>indirectly</td>\n",
       "      <td>False</td>\n",
       "      <td>categories_perplexity</td>\n",
       "      <td>categorise</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>stabilityai/StableBeluga-7B</td>\n",
       "      <td>0.688</td>\n",
       "      <td>0.649</td>\n",
       "      <td>0.736</td>\n",
       "      <td>0.580</td>\n",
       "      <td>0.401</td>\n",
       "      <td>distribution</td>\n",
       "      <td>arbitrary</td>\n",
       "      <td>False</td>\n",
       "      <td>categories_perplexity</td>\n",
       "      <td>categorise</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>stabilityai/StableBeluga-7B</td>\n",
       "      <td>0.685</td>\n",
       "      <td>0.661</td>\n",
       "      <td>0.711</td>\n",
       "      <td>0.618</td>\n",
       "      <td>0.388</td>\n",
       "      <td>distribution</td>\n",
       "      <td>directly</td>\n",
       "      <td>False</td>\n",
       "      <td>categories_perplexity</td>\n",
       "      <td>categorise</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      llm_name  accuracy     f1  precision  recall  \\\n",
       "2  stabilityai/StableBeluga-7B     0.697  0.703      0.687   0.720   \n",
       "1  stabilityai/StableBeluga-7B     0.688  0.649      0.736   0.580   \n",
       "0  stabilityai/StableBeluga-7B     0.685  0.661      0.711   0.618   \n",
       "\n",
       "   calibration_error    edge_value effect_type  finetuned  \\\n",
       "2              0.396  distribution  indirectly      False   \n",
       "1              0.401  distribution   arbitrary      False   \n",
       "0              0.388  distribution    directly      False   \n",
       "\n",
       "             parse_style prompt_style     uc  \n",
       "2  categories_perplexity   categorise  False  \n",
       "1  categories_perplexity   categorise  False  \n",
       "0  categories_perplexity   categorise  False  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>llm_name</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f1</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>calibration_error</th>\n",
       "      <th>edge_value</th>\n",
       "      <th>effect_type</th>\n",
       "      <th>finetuned</th>\n",
       "      <th>parse_style</th>\n",
       "      <th>prompt_style</th>\n",
       "      <th>uc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>stabilityai/StableBeluga-13B</td>\n",
       "      <td>0.644</td>\n",
       "      <td>0.722</td>\n",
       "      <td>0.591</td>\n",
       "      <td>0.928</td>\n",
       "      <td>0.446</td>\n",
       "      <td>distribution</td>\n",
       "      <td>directly</td>\n",
       "      <td>False</td>\n",
       "      <td>categories_perplexity</td>\n",
       "      <td>categorise</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>stabilityai/StableBeluga-13B</td>\n",
       "      <td>0.596</td>\n",
       "      <td>0.704</td>\n",
       "      <td>0.554</td>\n",
       "      <td>0.966</td>\n",
       "      <td>0.451</td>\n",
       "      <td>distribution</td>\n",
       "      <td>arbitrary</td>\n",
       "      <td>False</td>\n",
       "      <td>categories_perplexity</td>\n",
       "      <td>categorise</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>stabilityai/StableBeluga-13B</td>\n",
       "      <td>0.558</td>\n",
       "      <td>0.688</td>\n",
       "      <td>0.530</td>\n",
       "      <td>0.981</td>\n",
       "      <td>0.457</td>\n",
       "      <td>distribution</td>\n",
       "      <td>indirectly</td>\n",
       "      <td>False</td>\n",
       "      <td>categories_perplexity</td>\n",
       "      <td>categorise</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       llm_name  accuracy     f1  precision  recall  \\\n",
       "0  stabilityai/StableBeluga-13B     0.644  0.722      0.591   0.928   \n",
       "1  stabilityai/StableBeluga-13B     0.596  0.704      0.554   0.966   \n",
       "2  stabilityai/StableBeluga-13B     0.558  0.688      0.530   0.981   \n",
       "\n",
       "   calibration_error    edge_value effect_type  finetuned  \\\n",
       "0              0.446  distribution    directly      False   \n",
       "1              0.451  distribution   arbitrary      False   \n",
       "2              0.457  distribution  indirectly      False   \n",
       "\n",
       "             parse_style prompt_style     uc  \n",
       "0  categories_perplexity   categorise  False  \n",
       "1  categories_perplexity   categorise  False  \n",
       "2  categories_perplexity   categorise  False  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>llm_name</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f1</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>calibration_error</th>\n",
       "      <th>edge_value</th>\n",
       "      <th>effect_type</th>\n",
       "      <th>finetuned</th>\n",
       "      <th>parse_style</th>\n",
       "      <th>prompt_style</th>\n",
       "      <th>uc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>upstage/llama-30b-instruct-2048</td>\n",
       "      <td>0.721</td>\n",
       "      <td>0.698</td>\n",
       "      <td>0.757</td>\n",
       "      <td>0.647</td>\n",
       "      <td>0.318</td>\n",
       "      <td>distribution</td>\n",
       "      <td>directly</td>\n",
       "      <td>False</td>\n",
       "      <td>categories_perplexity</td>\n",
       "      <td>categorise</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          llm_name  accuracy     f1  precision  recall  \\\n",
       "0  upstage/llama-30b-instruct-2048     0.721  0.698      0.757   0.647   \n",
       "\n",
       "   calibration_error    edge_value effect_type  finetuned  \\\n",
       "0              0.318  distribution    directly      False   \n",
       "\n",
       "             parse_style prompt_style     uc  \n",
       "0  categories_perplexity   categorise  False  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Varying effect type\n",
    "# #Best 7bn Model\n",
    "li_exps_filt7b = filter_exp(li_all_experiments, llm_names=['7b'], parse_style=['categories_perplexity'], prompt_style=['categorise'], finetuned=[False], unbias_categorisations=[False] )\n",
    "li_exps_filt7b_w_res = calc_eval_metrics(li_exps_filt7b, metrics=['accuracy','precision','recall','f1', 'calibration_error'], average_type='binary' )\n",
    "df_exps_filt7b = convert_li_exp_to_df(li_exps_filt7b_w_res)\n",
    "# Sort by accuracy\n",
    "df_exps_filt7b.sort_values(by=['accuracy'], ascending=False, inplace=True)\n",
    "display(df_exps_filt7b.head(5).round(3) )\n",
    "print(\"\\n\")\n",
    "\n",
    "#Best 13bn Model\n",
    "li_exps_filt13b = filter_exp(li_all_experiments, llm_names=['13b'], parse_style=['categories_perplexity'], prompt_style=['categorise'], finetuned=[False], unbias_categorisations=[False] )\n",
    "li_exps_filt13b_w_res = calc_eval_metrics(li_exps_filt13b, metrics=['accuracy','precision','recall','f1','calibration_error'], average_type='binary' )\n",
    "df_exps_filt13b = convert_li_exp_to_df(li_exps_filt13b_w_res)\n",
    "# Sort by accuracy\n",
    "df_exps_filt13b.sort_values(by=['accuracy'], ascending=False, inplace=True)\n",
    "display(df_exps_filt13b.head(5).round(3) )\n",
    "print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>llm_name</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f1</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>calibration_error</th>\n",
       "      <th>edge_value</th>\n",
       "      <th>effect_type</th>\n",
       "      <th>finetuned</th>\n",
       "      <th>parse_style</th>\n",
       "      <th>prompt_style</th>\n",
       "      <th>uc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>stabilityai/StableBeluga-7B</td>\n",
       "      <td>0.685</td>\n",
       "      <td>0.661</td>\n",
       "      <td>0.711</td>\n",
       "      <td>0.618</td>\n",
       "      <td>0.388</td>\n",
       "      <td>distribution</td>\n",
       "      <td>directly</td>\n",
       "      <td>False</td>\n",
       "      <td>categories_perplexity</td>\n",
       "      <td>categorise</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>stabilityai/StableBeluga-7B</td>\n",
       "      <td>0.538</td>\n",
       "      <td>0.186</td>\n",
       "      <td>0.759</td>\n",
       "      <td>0.106</td>\n",
       "      <td>0.429</td>\n",
       "      <td>distribution</td>\n",
       "      <td>directly</td>\n",
       "      <td>False</td>\n",
       "      <td>categories_perplexity</td>\n",
       "      <td>categorise</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      llm_name  accuracy     f1  precision  recall  \\\n",
       "1  stabilityai/StableBeluga-7B     0.685  0.661      0.711   0.618   \n",
       "0  stabilityai/StableBeluga-7B     0.538  0.186      0.759   0.106   \n",
       "\n",
       "   calibration_error    edge_value effect_type  finetuned  \\\n",
       "1              0.388  distribution    directly      False   \n",
       "0              0.429  distribution    directly      False   \n",
       "\n",
       "             parse_style prompt_style     uc  \n",
       "1  categories_perplexity   categorise  False  \n",
       "0  categories_perplexity   categorise   True  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>llm_name</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f1</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>calibration_error</th>\n",
       "      <th>edge_value</th>\n",
       "      <th>effect_type</th>\n",
       "      <th>finetuned</th>\n",
       "      <th>parse_style</th>\n",
       "      <th>prompt_style</th>\n",
       "      <th>uc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>stabilityai/StableBeluga-13B</td>\n",
       "      <td>0.644</td>\n",
       "      <td>0.722</td>\n",
       "      <td>0.591</td>\n",
       "      <td>0.928</td>\n",
       "      <td>0.446</td>\n",
       "      <td>distribution</td>\n",
       "      <td>directly</td>\n",
       "      <td>False</td>\n",
       "      <td>categories_perplexity</td>\n",
       "      <td>categorise</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>stabilityai/StableBeluga-13B</td>\n",
       "      <td>0.507</td>\n",
       "      <td>0.038</td>\n",
       "      <td>0.667</td>\n",
       "      <td>0.019</td>\n",
       "      <td>0.463</td>\n",
       "      <td>distribution</td>\n",
       "      <td>directly</td>\n",
       "      <td>False</td>\n",
       "      <td>categories_perplexity</td>\n",
       "      <td>categorise</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       llm_name  accuracy     f1  precision  recall  \\\n",
       "1  stabilityai/StableBeluga-13B     0.644  0.722      0.591   0.928   \n",
       "0  stabilityai/StableBeluga-13B     0.507  0.038      0.667   0.019   \n",
       "\n",
       "   calibration_error    edge_value effect_type  finetuned  \\\n",
       "1              0.446  distribution    directly      False   \n",
       "0              0.463  distribution    directly      False   \n",
       "\n",
       "             parse_style prompt_style     uc  \n",
       "1  categories_perplexity   categorise  False  \n",
       "0  categories_perplexity   categorise   True  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>llm_name</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f1</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>calibration_error</th>\n",
       "      <th>edge_value</th>\n",
       "      <th>effect_type</th>\n",
       "      <th>finetuned</th>\n",
       "      <th>parse_style</th>\n",
       "      <th>prompt_style</th>\n",
       "      <th>uc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>upstage/llama-30b-instruct-2048</td>\n",
       "      <td>0.721</td>\n",
       "      <td>0.703</td>\n",
       "      <td>0.749</td>\n",
       "      <td>0.662</td>\n",
       "      <td>0.331</td>\n",
       "      <td>distribution</td>\n",
       "      <td>directly</td>\n",
       "      <td>False</td>\n",
       "      <td>categories_perplexity</td>\n",
       "      <td>categorise</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>upstage/llama-30b-instruct-2048</td>\n",
       "      <td>0.721</td>\n",
       "      <td>0.698</td>\n",
       "      <td>0.757</td>\n",
       "      <td>0.647</td>\n",
       "      <td>0.318</td>\n",
       "      <td>distribution</td>\n",
       "      <td>directly</td>\n",
       "      <td>False</td>\n",
       "      <td>categories_perplexity</td>\n",
       "      <td>categorise</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          llm_name  accuracy     f1  precision  recall  \\\n",
       "0  upstage/llama-30b-instruct-2048     0.721  0.703      0.749   0.662   \n",
       "1  upstage/llama-30b-instruct-2048     0.721  0.698      0.757   0.647   \n",
       "\n",
       "   calibration_error    edge_value effect_type  finetuned  \\\n",
       "0              0.331  distribution    directly      False   \n",
       "1              0.318  distribution    directly      False   \n",
       "\n",
       "             parse_style prompt_style     uc  \n",
       "0  categories_perplexity   categorise   True  \n",
       "1  categories_perplexity   categorise  False  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Varying unbiased categorisations\n",
    "# #Best 7bn Model\n",
    "li_exps_filt7b = filter_exp(li_all_experiments, llm_names=['7b'], parse_style=['categories_perplexity'], prompt_style=['categorise'], finetuned=[False], effect_type=['directly'] )\n",
    "li_exps_filt7b_w_res = calc_eval_metrics(li_exps_filt7b, metrics=['accuracy','precision','recall','f1', 'calibration_error'], average_type='binary' )\n",
    "df_exps_filt7b = convert_li_exp_to_df(li_exps_filt7b_w_res)\n",
    "# Sort by accuracy\n",
    "df_exps_filt7b.sort_values(by=['accuracy'], ascending=False, inplace=True)\n",
    "display(df_exps_filt7b.head(5).round(3) )\n",
    "print(\"\\n\")\n",
    "\n",
    "#Best 13bn Model\n",
    "li_exps_filt13b = filter_exp(li_all_experiments, llm_names=['13b'], parse_style=['categories_perplexity'], prompt_style=['categorise'], finetuned=[False], effect_type=['directly'] )\n",
    "li_exps_filt13b_w_res = calc_eval_metrics(li_exps_filt13b, metrics=['accuracy','precision','recall','f1','calibration_error'], average_type='binary' )\n",
    "df_exps_filt13b = convert_li_exp_to_df(li_exps_filt13b_w_res)\n",
    "# Sort by accuracy\n",
    "df_exps_filt13b.sort_values(by=['accuracy'], ascending=False, inplace=True)\n",
    "display(df_exps_filt13b.head(5).round(3) )\n",
    "print(\"\\n\")\n",
    "\n",
    "# #Best 30bn Model\n",
    "li_exps_filt30b = filter_exp(li_all_experiments, llm_names=['30b','60b','70b'],  parse_style=['categories_perplexity'],prompt_style=['categorise'], finetuned=[False], effect_type=['directly'] ) \n",
    "li_exps_filt30b_w_res = calc_eval_metrics(li_exps_filt30b, metrics=['accuracy','precision','recall','f1', 'calibration_error'], average_type='binary' )\n",
    "df_exps_filt30b = convert_li_exp_to_df(li_exps_filt30b_w_res)\n",
    "# Sort by accuracy\n",
    "df_exps_filt30b.sort_values(by=['accuracy'], ascending=False, inplace=True)\n",
    "display(df_exps_filt30b.head(6).round(3), )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>llm_name</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f1</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>calibration_error</th>\n",
       "      <th>edge_value</th>\n",
       "      <th>effect_type</th>\n",
       "      <th>finetuned</th>\n",
       "      <th>parse_style</th>\n",
       "      <th>prompt_style</th>\n",
       "      <th>uc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>stabilityai/StableBeluga-7B</td>\n",
       "      <td>0.697</td>\n",
       "      <td>0.703</td>\n",
       "      <td>0.687</td>\n",
       "      <td>0.720</td>\n",
       "      <td>0.396</td>\n",
       "      <td>distribution</td>\n",
       "      <td>indirectly</td>\n",
       "      <td>False</td>\n",
       "      <td>categories_perplexity</td>\n",
       "      <td>categorise</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>stabilityai/StableBeluga-7B</td>\n",
       "      <td>0.695</td>\n",
       "      <td>0.705</td>\n",
       "      <td>0.679</td>\n",
       "      <td>0.734</td>\n",
       "      <td>0.410</td>\n",
       "      <td>distribution</td>\n",
       "      <td>indirectly</td>\n",
       "      <td>True</td>\n",
       "      <td>categories_perplexity</td>\n",
       "      <td>categorise</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>stabilityai/StableBeluga-7B</td>\n",
       "      <td>0.666</td>\n",
       "      <td>0.734</td>\n",
       "      <td>0.608</td>\n",
       "      <td>0.928</td>\n",
       "      <td>0.334</td>\n",
       "      <td>binary_weight</td>\n",
       "      <td>indirectly</td>\n",
       "      <td>True</td>\n",
       "      <td>rules</td>\n",
       "      <td>yes_no</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>stabilityai/StableBeluga-7B</td>\n",
       "      <td>0.661</td>\n",
       "      <td>0.734</td>\n",
       "      <td>0.602</td>\n",
       "      <td>0.942</td>\n",
       "      <td>0.339</td>\n",
       "      <td>binary_weight</td>\n",
       "      <td>indirectly</td>\n",
       "      <td>False</td>\n",
       "      <td>rules</td>\n",
       "      <td>yes_no</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>stabilityai/StableBeluga-7B</td>\n",
       "      <td>0.522</td>\n",
       "      <td>0.673</td>\n",
       "      <td>0.510</td>\n",
       "      <td>0.990</td>\n",
       "      <td>0.478</td>\n",
       "      <td>binary_weight</td>\n",
       "      <td>indirectly</td>\n",
       "      <td>True</td>\n",
       "      <td>categories_rules</td>\n",
       "      <td>open</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      llm_name  accuracy     f1  precision  recall  \\\n",
       "2  stabilityai/StableBeluga-7B     0.697  0.703      0.687   0.720   \n",
       "6  stabilityai/StableBeluga-7B     0.695  0.705      0.679   0.734   \n",
       "4  stabilityai/StableBeluga-7B     0.666  0.734      0.608   0.928   \n",
       "0  stabilityai/StableBeluga-7B     0.661  0.734      0.602   0.942   \n",
       "5  stabilityai/StableBeluga-7B     0.522  0.673      0.510   0.990   \n",
       "\n",
       "   calibration_error     edge_value effect_type  finetuned  \\\n",
       "2              0.396   distribution  indirectly      False   \n",
       "6              0.410   distribution  indirectly       True   \n",
       "4              0.334  binary_weight  indirectly       True   \n",
       "0              0.339  binary_weight  indirectly      False   \n",
       "5              0.478  binary_weight  indirectly       True   \n",
       "\n",
       "             parse_style prompt_style     uc  \n",
       "2  categories_perplexity   categorise  False  \n",
       "6  categories_perplexity   categorise  False  \n",
       "4                  rules       yes_no  False  \n",
       "0                  rules       yes_no  False  \n",
       "5       categories_rules         open  False  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>llm_name</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f1</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>calibration_error</th>\n",
       "      <th>edge_value</th>\n",
       "      <th>effect_type</th>\n",
       "      <th>finetuned</th>\n",
       "      <th>parse_style</th>\n",
       "      <th>prompt_style</th>\n",
       "      <th>uc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>stabilityai/StableBeluga-13B</td>\n",
       "      <td>0.654</td>\n",
       "      <td>0.732</td>\n",
       "      <td>0.595</td>\n",
       "      <td>0.952</td>\n",
       "      <td>0.346</td>\n",
       "      <td>binary_weight</td>\n",
       "      <td>indirectly</td>\n",
       "      <td>True</td>\n",
       "      <td>rules</td>\n",
       "      <td>yes_no</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>stabilityai/StableBeluga-13B</td>\n",
       "      <td>0.651</td>\n",
       "      <td>0.731</td>\n",
       "      <td>0.593</td>\n",
       "      <td>0.952</td>\n",
       "      <td>0.349</td>\n",
       "      <td>binary_weight</td>\n",
       "      <td>indirectly</td>\n",
       "      <td>False</td>\n",
       "      <td>rules</td>\n",
       "      <td>yes_no</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>stabilityai/StableBeluga-13B</td>\n",
       "      <td>0.562</td>\n",
       "      <td>0.692</td>\n",
       "      <td>0.533</td>\n",
       "      <td>0.986</td>\n",
       "      <td>0.458</td>\n",
       "      <td>distribution</td>\n",
       "      <td>indirectly</td>\n",
       "      <td>True</td>\n",
       "      <td>categories_perplexity</td>\n",
       "      <td>categorise</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>stabilityai/StableBeluga-13B</td>\n",
       "      <td>0.558</td>\n",
       "      <td>0.688</td>\n",
       "      <td>0.530</td>\n",
       "      <td>0.981</td>\n",
       "      <td>0.457</td>\n",
       "      <td>distribution</td>\n",
       "      <td>indirectly</td>\n",
       "      <td>False</td>\n",
       "      <td>categories_perplexity</td>\n",
       "      <td>categorise</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>stabilityai/StableBeluga-13B</td>\n",
       "      <td>0.510</td>\n",
       "      <td>0.669</td>\n",
       "      <td>0.504</td>\n",
       "      <td>0.995</td>\n",
       "      <td>0.490</td>\n",
       "      <td>binary_weight</td>\n",
       "      <td>indirectly</td>\n",
       "      <td>True</td>\n",
       "      <td>categories_rules</td>\n",
       "      <td>open</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       llm_name  accuracy     f1  precision  recall  \\\n",
       "0  stabilityai/StableBeluga-13B     0.654  0.732      0.595   0.952   \n",
       "4  stabilityai/StableBeluga-13B     0.651  0.731      0.593   0.952   \n",
       "2  stabilityai/StableBeluga-13B     0.562  0.692      0.533   0.986   \n",
       "6  stabilityai/StableBeluga-13B     0.558  0.688      0.530   0.981   \n",
       "1  stabilityai/StableBeluga-13B     0.510  0.669      0.504   0.995   \n",
       "\n",
       "   calibration_error     edge_value effect_type  finetuned  \\\n",
       "0              0.346  binary_weight  indirectly       True   \n",
       "4              0.349  binary_weight  indirectly      False   \n",
       "2              0.458   distribution  indirectly       True   \n",
       "6              0.457   distribution  indirectly      False   \n",
       "1              0.490  binary_weight  indirectly       True   \n",
       "\n",
       "             parse_style prompt_style     uc  \n",
       "0                  rules       yes_no  False  \n",
       "4                  rules       yes_no  False  \n",
       "2  categories_perplexity   categorise  False  \n",
       "6  categories_perplexity   categorise  False  \n",
       "1       categories_rules         open  False  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Varying finetuned\n",
    "# #Best 7bn Model\n",
    "li_exps_filt7b = filter_exp(li_all_experiments, llm_names=['7b'],  effect_type=['indirectly'], unbias_categorisations=[False] )\n",
    "li_exps_filt7b_w_res = calc_eval_metrics(li_exps_filt7b, metrics=['accuracy','precision','recall','f1', 'calibration_error'], average_type='binary' )\n",
    "df_exps_filt7b = convert_li_exp_to_df(li_exps_filt7b_w_res)\n",
    "# Sort by accuracy\n",
    "df_exps_filt7b.sort_values(by=['accuracy'], ascending=False, inplace=True)\n",
    "display(df_exps_filt7b.head(5).round(3) )\n",
    "print(\"\\n\")\n",
    "\n",
    "#Best 13bn Model\n",
    "li_exps_filt13b = filter_exp(li_all_experiments, llm_names=['13b'],  effect_type=['indirectly'], unbias_categorisations=[False] )\n",
    "li_exps_filt13b_w_res = calc_eval_metrics(li_exps_filt13b, metrics=['accuracy','precision','recall','f1','calibration_error'], average_type='binary' )\n",
    "df_exps_filt13b = convert_li_exp_to_df(li_exps_filt13b_w_res)\n",
    "# Sort by accuracy\n",
    "df_exps_filt13b.sort_values(by=['accuracy'], ascending=False, inplace=True)\n",
    "display(df_exps_filt13b.head(5).round(3) )\n",
    "print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) Accuracy, F1, Precision and Recall [ non-probabilistic / non-finetuned and finetuned with varied parse_style_prompt_style but effect type == 'directly' ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0      1.0\n",
      "1      0.0\n",
      "2      0.0\n",
      "3      0.0\n",
      "4      0.0\n",
      "      ... \n",
      "411    0.0\n",
      "412    0.0\n",
      "413    1.0\n",
      "414    1.0\n",
      "415    1.0\n",
      "Name: related_prob, Length: 416, dtype: float64 \n",
      "\n",
      "\n",
      "0      1.0\n",
      "1      1.0\n",
      "2      1.0\n",
      "3      1.0\n",
      "4      1.0\n",
      "      ... \n",
      "411    1.0\n",
      "412    1.0\n",
      "413    1.0\n",
      "414    1.0\n",
      "415    1.0\n",
      "Name: pred_prob, Length: 416, dtype: float64 \n",
      "\n",
      "\n",
      "0      0.0\n",
      "1      1.0\n",
      "2      1.0\n",
      "3      1.0\n",
      "4      1.0\n",
      "      ... \n",
      "411    1.0\n",
      "412    1.0\n",
      "413    0.0\n",
      "414    0.0\n",
      "415    0.0\n",
      "Length: 416, dtype: float64 \n",
      "\n",
      "\n",
      "[0. 1. 1. 1. 1. 0. 1. 0. 0. 1. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 1. 1. 0.\n",
      " 0. 1. 0. 1. 1. 1. 0. 0. 1. 0. 0. 1. 0. 1. 1. 1. 1. 1. 0. 1. 1. 0. 0. 0.\n",
      " 1. 1. 0. 1. 0. 0. 1. 1. 1. 1. 0. 0. 1. 0. 1. 0. 0. 0. 1. 1. 0. 0. 1. 0.\n",
      " 1. 1. 0. 1. 1. 1. 0. 0. 0. 1. 1. 1. 0. 0. 1. 0. 1. 0. 0. 1. 0. 0. 0. 1.\n",
      " 1. 0. 1. 0. 0. 1. 1. 0. 1. 0. 1. 1. 1. 1. 0. 1. 1. 0. 1. 0. 1. 0. 1. 0.\n",
      " 0. 1. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 1. 1. 1. 0. 0. 0. 0. 0. 1. 1.\n",
      " 1. 0. 1. 1. 0. 1. 1. 1. 0. 1. 1. 1. 0. 0. 1. 1. 1. 1. 1. 1. 0. 1. 0. 1.\n",
      " 0. 0. 0. 0. 0. 1. 1. 0. 0. 1. 0. 0. 1. 1. 0. 0. 0. 1. 1. 0. 0. 1. 1. 1.\n",
      " 0. 0. 1. 1. 1. 0. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 1. 0. 1. 0. 0.\n",
      " 1. 1. 0. 1. 0. 1. 0. 1. 1. 0. 0. 0. 1. 1. 0. 1. 0. 0. 1. 0. 0. 0. 1. 1.\n",
      " 0. 0. 0. 0. 1. 1. 0. 1. 1. 1. 1. 1. 1. 0. 1. 0. 0. 1. 1. 1. 0. 0. 1. 0.\n",
      " 0. 0. 1. 1. 1. 1. 0. 1. 0. 1. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 1. 1. 0.\n",
      " 0. 1. 1. 1. 0. 0. 0. 0. 1. 1. 1. 0. 1. 1. 1. 1. 0. 1. 0. 1. 1. 1. 0. 0.\n",
      " 1. 1. 1. 1. 0. 0. 0. 1. 1. 1. 1. 1. 0. 0. 1. 1. 1. 0. 1. 0. 0. 0. 1. 1.\n",
      " 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 0. 0. 1. 0. 0. 1. 1. 1. 0. 1. 0. 0.\n",
      " 0. 1. 0. 0. 1. 1. 1. 0. 0. 0. 0. 1. 1. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0.\n",
      " 0. 1. 1. 1. 0. 0. 1. 1. 1. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 0. 1. 0. 1. 1.\n",
      " 1. 1. 0. 1. 1. 0. 0. 0.] \n",
      "\n",
      "\n",
      "0.5024038461538461 \n",
      "\n",
      "\n",
      "0      1.0\n",
      "1      0.0\n",
      "2      0.0\n",
      "3      0.0\n",
      "4      0.0\n",
      "      ... \n",
      "411    0.0\n",
      "412    0.0\n",
      "413    1.0\n",
      "414    1.0\n",
      "415    1.0\n",
      "Name: related_prob, Length: 416, dtype: float64 \n",
      "\n",
      "\n",
      "0      0.721\n",
      "1      0.911\n",
      "2      0.886\n",
      "3      0.973\n",
      "4      0.996\n",
      "       ...  \n",
      "411    0.985\n",
      "412    0.936\n",
      "413    0.529\n",
      "414    0.828\n",
      "415    0.624\n",
      "Name: pred_prob, Length: 416, dtype: float64 \n",
      "\n",
      "\n",
      "0      0.279\n",
      "1      0.911\n",
      "2      0.886\n",
      "3      0.973\n",
      "4      0.996\n",
      "       ...  \n",
      "411    0.985\n",
      "412    0.936\n",
      "413    0.471\n",
      "414    0.172\n",
      "415    0.376\n",
      "Length: 416, dtype: float64 \n",
      "\n",
      "\n",
      "[0.279 0.911 0.886 0.973 0.996 0.048 0.974 0.256 0.226 0.83  0.775 0.146\n",
      " 0.185 0.966 0.187 0.277 0.117 0.444 0.047 0.201 0.568 0.806 0.988 0.16\n",
      " 0.449 0.989 0.187 0.988 0.967 0.643 0.295 0.263 0.988 0.383 0.5   0.973\n",
      " 0.118 0.984 0.982 0.546 0.946 0.911 0.127 0.978 0.504 0.255 0.283 0.225\n",
      " 0.92  0.763 0.479 0.842 0.055 0.156 0.513 0.607 0.989 0.962 0.225 0.358\n",
      " 0.665 0.158 0.968 0.309 0.309 0.486 0.982 0.962 0.399 0.05  0.989 0.278\n",
      " 0.959 0.997 0.323 0.722 0.909 0.74  0.134 0.189 0.36  0.974 0.971 0.98\n",
      " 0.198 0.208 0.642 0.218 0.918 0.124 0.433 0.993 0.283 0.186 0.178 0.893\n",
      " 0.953 0.143 0.581 0.375 0.176 0.799 0.984 0.236 0.983 0.302 0.99  0.74\n",
      " 0.911 0.804 0.283 0.895 0.581 0.378 0.707 0.063 0.942 0.147 0.861 0.175\n",
      " 0.055 0.9   0.223 0.802 0.492 0.298 0.152 0.194 0.89  0.247 0.398 0.191\n",
      " 0.862 0.281 0.866 0.938 0.648 0.428 0.352 0.163 0.19  0.333 0.983 0.985\n",
      " 0.953 0.175 0.847 0.681 0.165 0.65  0.809 0.74  0.149 0.961 0.525 0.868\n",
      " 0.356 0.343 0.955 0.549 0.979 0.992 0.995 0.633 0.209 0.837 0.22  0.636\n",
      " 0.081 0.02  0.436 0.178 0.172 0.965 0.937 0.094 0.338 0.66  0.194 0.436\n",
      " 0.849 0.98  0.029 0.26  0.222 0.909 0.957 0.397 0.459 0.991 0.528 0.78\n",
      " 0.334 0.225 0.699 0.751 0.639 0.362 0.94  0.669 0.151 0.485 0.276 0.145\n",
      " 0.352 0.909 0.32  0.093 0.45  0.949 0.204 0.932 0.457 0.967 0.09  0.352\n",
      " 0.987 0.907 0.285 0.969 0.029 0.562 0.27  0.994 0.596 0.168 0.333 0.354\n",
      " 0.676 0.956 0.082 0.99  0.062 0.205 0.952 0.363 0.195 0.309 0.948 0.828\n",
      " 0.063 0.324 0.46  0.268 0.532 0.993 0.132 0.812 0.991 0.94  0.686 0.972\n",
      " 0.82  0.353 0.967 0.365 0.176 0.724 0.556 0.952 0.33  0.414 0.825 0.134\n",
      " 0.247 0.338 0.881 0.978 0.995 0.7   0.114 0.991 0.028 0.93  0.384 0.356\n",
      " 0.268 0.455 0.983 0.108 0.963 0.234 0.2   0.29  0.261 0.975 0.763 0.133\n",
      " 0.067 0.644 0.985 0.809 0.188 0.1   0.386 0.44  0.997 0.99  0.987 0.081\n",
      " 0.993 0.986 0.681 0.995 0.427 0.666 0.104 0.968 0.938 0.94  0.163 0.122\n",
      " 0.976 0.985 0.73  0.993 0.254 0.009 0.128 0.801 0.958 0.579 0.84  0.943\n",
      " 0.42  0.448 0.85  0.594 0.857 0.207 0.731 0.275 0.34  0.322 0.961 0.949\n",
      " 0.232 0.284 0.254 0.273 0.911 0.198 0.149 0.263 0.738 0.617 0.634 0.611\n",
      " 0.093 0.408 0.857 0.22  0.112 0.919 0.788 0.846 0.382 0.807 0.234 0.387\n",
      " 0.103 0.878 0.411 0.079 0.705 0.966 0.96  0.191 0.267 0.145 0.337 0.744\n",
      " 0.664 0.123 0.258 0.37  0.989 0.281 0.2   0.279 0.87  0.073 0.337 0.494\n",
      " 0.221 0.997 0.596 0.977 0.077 0.12  0.981 0.523 0.741 0.97  0.374 0.169\n",
      " 0.025 0.943 0.86  0.991 0.625 0.866 0.975 0.18  0.796 0.349 0.995 0.829\n",
      " 0.943 0.962 0.249 0.985 0.936 0.471 0.172 0.376] \n",
      "\n",
      "\n",
      "0.5524567307692307 \n",
      "\n",
      "\n",
      "0      1.0\n",
      "1      0.0\n",
      "2      0.0\n",
      "3      0.0\n",
      "4      0.0\n",
      "      ... \n",
      "411    0.0\n",
      "412    0.0\n",
      "413    1.0\n",
      "414    1.0\n",
      "415    1.0\n",
      "Name: related_prob, Length: 416, dtype: float64 \n",
      "\n",
      "\n",
      "0      0.746\n",
      "1      0.975\n",
      "2      0.956\n",
      "3      0.996\n",
      "4      0.999\n",
      "       ...  \n",
      "411    0.997\n",
      "412    0.980\n",
      "413    0.585\n",
      "414    0.835\n",
      "415    0.630\n",
      "Name: pred_prob, Length: 416, dtype: float64 \n",
      "\n",
      "\n",
      "0      0.254\n",
      "1      0.975\n",
      "2      0.956\n",
      "3      0.996\n",
      "4      0.999\n",
      "       ...  \n",
      "411    0.997\n",
      "412    0.980\n",
      "413    0.415\n",
      "414    0.165\n",
      "415    0.370\n",
      "Length: 416, dtype: float64 \n",
      "\n",
      "\n",
      "[0.254 0.975 0.956 0.996 0.999 0.013 0.998 0.215 0.209 0.877 0.854 0.062\n",
      " 0.162 0.996 0.076 0.272 0.057 0.4   0.023 0.129 0.539 0.844 0.998 0.11\n",
      " 0.43  0.996 0.129 0.997 0.988 0.608 0.272 0.228 0.996 0.328 0.419 0.994\n",
      " 0.056 0.995 0.995 0.626 0.983 0.987 0.052 0.997 0.527 0.209 0.231 0.242\n",
      " 0.989 0.867 0.438 0.91  0.017 0.093 0.589 0.63  0.997 0.991 0.146 0.363\n",
      " 0.672 0.095 0.994 0.288 0.251 0.469 0.998 0.972 0.453 0.008 0.998 0.182\n",
      " 0.983 0.999 0.304 0.818 0.965 0.74  0.064 0.108 0.317 0.994 0.993 0.995\n",
      " 0.176 0.209 0.706 0.167 0.962 0.057 0.484 0.998 0.297 0.212 0.116 0.948\n",
      " 0.982 0.089 0.566 0.426 0.107 0.874 0.997 0.215 0.997 0.331 0.998 0.824\n",
      " 0.973 0.877 0.281 0.955 0.604 0.438 0.719 0.01  0.988 0.044 0.945 0.124\n",
      " 0.009 0.955 0.158 0.801 0.457 0.281 0.093 0.119 0.935 0.11  0.392 0.075\n",
      " 0.93  0.248 0.953 0.973 0.637 0.321 0.363 0.108 0.123 0.345 0.997 0.995\n",
      " 0.99  0.07  0.881 0.766 0.116 0.651 0.876 0.824 0.091 0.988 0.516 0.93\n",
      " 0.352 0.349 0.985 0.539 0.997 0.997 0.998 0.669 0.16  0.892 0.156 0.737\n",
      " 0.025 0.006 0.449 0.126 0.113 0.99  0.98  0.053 0.294 0.715 0.128 0.484\n",
      " 0.926 0.995 0.008 0.275 0.167 0.975 0.981 0.43  0.488 0.997 0.622 0.844\n",
      " 0.301 0.171 0.709 0.806 0.651 0.442 0.971 0.658 0.083 0.442 0.245 0.084\n",
      " 0.307 0.957 0.288 0.047 0.404 0.986 0.16  0.973 0.457 0.988 0.047 0.301\n",
      " 0.997 0.988 0.217 0.99  0.011 0.577 0.239 0.998 0.554 0.121 0.251 0.278\n",
      " 0.719 0.989 0.038 0.997 0.018 0.171 0.99  0.356 0.144 0.234 0.976 0.872\n",
      " 0.016 0.338 0.48  0.285 0.543 0.998 0.113 0.917 0.998 0.985 0.734 0.992\n",
      " 0.931 0.328 0.993 0.311 0.119 0.801 0.52  0.981 0.223 0.331 0.92  0.079\n",
      " 0.182 0.294 0.943 0.998 0.999 0.788 0.044 0.998 0.009 0.977 0.291 0.297\n",
      " 0.281 0.426 0.997 0.052 0.997 0.088 0.135 0.239 0.228 0.996 0.775 0.061\n",
      " 0.038 0.665 0.996 0.916 0.14  0.045 0.345 0.492 0.999 0.998 0.996 0.027\n",
      " 0.998 0.996 0.679 0.998 0.328 0.743 0.045 0.996 0.981 0.981 0.086 0.062\n",
      " 0.995 0.992 0.703 0.997 0.257 0.005 0.049 0.85  0.988 0.669 0.964 0.967\n",
      " 0.363 0.43  0.94  0.676 0.962 0.18  0.749 0.26  0.342 0.359 0.993 0.982\n",
      " 0.192 0.182 0.207 0.228 0.97  0.129 0.082 0.285 0.824 0.676 0.703 0.626\n",
      " 0.055 0.301 0.912 0.18  0.045 0.975 0.854 0.959 0.345 0.85  0.165 0.423\n",
      " 0.045 0.953 0.342 0.028 0.737 0.991 0.987 0.084 0.234 0.113 0.301 0.833\n",
      " 0.725 0.071 0.215 0.356 0.995 0.22  0.154 0.212 0.943 0.04  0.314 0.461\n",
      " 0.231 0.999 0.554 0.995 0.027 0.048 0.996 0.554 0.81  0.993 0.356 0.104\n",
      " 0.009 0.987 0.914 0.996 0.693 0.951 0.998 0.118 0.879 0.275 0.996 0.858\n",
      " 0.993 0.987 0.204 0.997 0.98  0.415 0.165 0.37 ] \n",
      "\n",
      "\n",
      "0.5507067307692307 \n",
      "\n",
      "\n",
      "0      1.0\n",
      "1      0.0\n",
      "2      0.0\n",
      "3      0.0\n",
      "4      0.0\n",
      "      ... \n",
      "411    0.0\n",
      "412    0.0\n",
      "413    1.0\n",
      "414    1.0\n",
      "415    1.0\n",
      "Name: related_prob, Length: 416, dtype: float64 \n",
      "\n",
      "\n",
      "0      1.0\n",
      "1      1.0\n",
      "2      1.0\n",
      "3      1.0\n",
      "4      1.0\n",
      "      ... \n",
      "411    1.0\n",
      "412    1.0\n",
      "413    1.0\n",
      "414    1.0\n",
      "415    1.0\n",
      "Name: pred_prob, Length: 416, dtype: float64 \n",
      "\n",
      "\n",
      "0      0.0\n",
      "1      1.0\n",
      "2      1.0\n",
      "3      1.0\n",
      "4      1.0\n",
      "      ... \n",
      "411    1.0\n",
      "412    1.0\n",
      "413    0.0\n",
      "414    0.0\n",
      "415    0.0\n",
      "Length: 416, dtype: float64 \n",
      "\n",
      "\n",
      "[0. 1. 1. 1. 1. 0. 1. 0. 0. 1. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 1. 1. 0.\n",
      " 0. 1. 0. 1. 1. 1. 0. 0. 1. 0. 0. 1. 0. 1. 1. 1. 1. 1. 0. 1. 1. 0. 0. 0.\n",
      " 1. 1. 0. 1. 0. 0. 1. 1. 1. 1. 0. 0. 1. 0. 1. 0. 0. 0. 1. 1. 0. 0. 1. 0.\n",
      " 1. 1. 0. 1. 1. 1. 0. 0. 0. 1. 1. 1. 0. 0. 1. 0. 1. 0. 0. 1. 0. 0. 0. 1.\n",
      " 1. 0. 1. 0. 0. 1. 1. 0. 1. 0. 1. 1. 1. 1. 0. 1. 1. 0. 1. 0. 1. 0. 1. 0.\n",
      " 0. 1. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 1. 1. 1. 0. 0. 0. 0. 0. 1. 1.\n",
      " 1. 0. 1. 1. 0. 1. 1. 1. 0. 1. 1. 1. 0. 0. 1. 1. 1. 1. 1. 1. 0. 1. 0. 1.\n",
      " 0. 0. 0. 0. 0. 1. 1. 0. 0. 1. 0. 0. 1. 1. 0. 0. 0. 1. 1. 0. 0. 1. 1. 1.\n",
      " 0. 0. 1. 1. 1. 0. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 1. 0. 1. 0. 0.\n",
      " 1. 1. 0. 1. 0. 1. 0. 1. 1. 0. 0. 0. 1. 1. 0. 1. 0. 0. 1. 0. 0. 0. 1. 1.\n",
      " 0. 0. 0. 0. 1. 1. 0. 1. 1. 1. 1. 1. 1. 0. 1. 0. 0. 1. 1. 1. 0. 0. 1. 0.\n",
      " 0. 0. 1. 1. 1. 1. 0. 1. 0. 1. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 1. 1. 0.\n",
      " 0. 1. 1. 1. 0. 0. 0. 0. 1. 1. 1. 0. 1. 1. 1. 1. 0. 1. 0. 1. 1. 1. 0. 0.\n",
      " 1. 1. 1. 1. 0. 0. 0. 1. 1. 1. 1. 1. 0. 0. 1. 1. 1. 0. 1. 0. 0. 0. 1. 1.\n",
      " 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 0. 0. 1. 0. 0. 1. 1. 1. 0. 1. 0. 0.\n",
      " 0. 1. 0. 0. 1. 1. 1. 0. 0. 0. 0. 1. 1. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0.\n",
      " 0. 1. 1. 1. 0. 0. 1. 1. 1. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 0. 1. 0. 1. 1.\n",
      " 1. 1. 0. 1. 1. 0. 0. 0.] \n",
      "\n",
      "\n",
      "0.5024038461538461 \n",
      "\n",
      "\n",
      "0      1.0\n",
      "1      0.0\n",
      "2      0.0\n",
      "3      0.0\n",
      "4      0.0\n",
      "      ... \n",
      "411    0.0\n",
      "412    0.0\n",
      "413    1.0\n",
      "414    1.0\n",
      "415    1.0\n",
      "Name: related_prob, Length: 416, dtype: float64 \n",
      "\n",
      "\n",
      "0      1.000\n",
      "1      0.997\n",
      "2      1.000\n",
      "3      0.998\n",
      "4      0.950\n",
      "       ...  \n",
      "411    0.999\n",
      "412    0.999\n",
      "413    1.000\n",
      "414    1.000\n",
      "415    0.999\n",
      "Name: pred_prob, Length: 416, dtype: float64 \n",
      "\n",
      "\n",
      "0      0.000\n",
      "1      0.997\n",
      "2      1.000\n",
      "3      0.998\n",
      "4      0.950\n",
      "       ...  \n",
      "411    0.999\n",
      "412    0.999\n",
      "413    0.000\n",
      "414    0.000\n",
      "415    0.001\n",
      "Length: 416, dtype: float64 \n",
      "\n",
      "\n",
      "[0.    0.997 1.    0.998 0.95  0.006 1.    0.    0.    0.653 0.999 0.\n",
      " 0.    0.98  0.    0.    0.    0.    0.006 0.    0.999 1.    0.998 0.\n",
      " 0.    0.989 0.    0.997 0.999 0.999 0.    0.    0.998 0.001 0.    0.966\n",
      " 0.    0.998 0.99  0.999 0.999 0.999 0.002 1.    1.    0.    0.    0.\n",
      " 0.998 0.998 0.    1.    0.043 0.    0.992 1.    0.994 0.998 0.001 0.\n",
      " 0.999 0.    0.999 0.    0.001 0.001 1.    1.    0.499 0.    0.999 0.\n",
      " 0.977 0.999 0.    1.    0.994 0.999 0.    0.    0.    0.998 0.999 0.997\n",
      " 0.007 0.001 0.999 0.001 1.    0.001 0.    0.993 0.001 0.    0.    0.991\n",
      " 0.998 0.    1.    0.    0.    0.994 0.999 0.    0.98  0.    0.769 0.999\n",
      " 0.994 1.    0.001 1.    1.    0.    1.    0.    0.994 0.002 1.    0.\n",
      " 0.    0.998 0.    0.994 0.    0.001 0.    0.    1.    0.    0.    0.\n",
      " 0.992 0.    0.999 0.999 1.    0.    0.    0.002 0.    0.    0.996 0.961\n",
      " 0.998 0.    0.992 0.999 0.    1.    1.    0.999 0.003 0.998 1.    0.981\n",
      " 0.003 0.001 0.996 1.    1.    0.999 0.979 1.    0.    0.998 0.    0.999\n",
      " 0.    0.01  0.003 0.    0.    0.996 0.996 0.001 0.    0.999 0.001 0.\n",
      " 0.977 1.    0.147 0.001 0.004 0.983 0.996 0.    0.001 0.998 1.    1.\n",
      " 0.    0.    1.    1.    1.    0.    0.99  0.999 0.001 0.001 0.    0.\n",
      " 0.    0.996 0.    0.001 0.002 1.    0.    1.    0.    0.999 0.001 0.\n",
      " 0.997 0.991 0.    0.999 0.001 1.    0.    0.995 1.    0.    0.    0.\n",
      " 0.999 0.999 0.    0.998 0.005 0.    1.    0.    0.    0.    0.99  1.\n",
      " 0.005 0.    0.    0.    0.975 1.    0.    0.994 0.997 0.994 1.    0.999\n",
      " 0.989 0.001 0.916 0.002 0.    0.993 1.    0.998 0.001 0.001 0.982 0.\n",
      " 0.    0.    0.991 0.985 0.989 1.    0.    0.997 0.335 0.998 0.    0.12\n",
      " 0.    0.001 0.966 0.    1.    0.001 0.    0.    0.001 0.997 0.999 0.\n",
      " 0.    0.999 0.987 0.999 0.    0.    0.002 0.    0.999 0.997 0.999 0.005\n",
      " 1.    0.996 1.    1.    0.001 0.999 0.    0.983 0.995 0.999 0.    0.\n",
      " 0.997 0.93  1.    1.    0.    0.004 0.422 1.    0.943 0.999 1.    0.637\n",
      " 0.    0.    0.987 1.    0.993 0.    1.    0.    0.442 0.001 0.998 0.997\n",
      " 0.016 0.    0.    0.002 0.975 0.    0.48  0.    0.999 1.    1.    1.\n",
      " 0.    0.    1.    0.    0.    1.    1.    1.    0.    0.969 0.    0.001\n",
      " 0.001 1.    0.001 0.001 0.992 1.    0.999 0.001 0.001 0.001 0.007 1.\n",
      " 1.    0.    0.    0.    1.    0.448 0.    0.    1.    0.069 0.    0.\n",
      " 0.    1.    1.    0.998 0.007 0.003 1.    1.    0.997 0.998 0.    0.\n",
      " 0.001 0.999 1.    1.    1.    0.707 1.    0.    1.    0.    0.999 1.\n",
      " 0.982 0.994 0.    0.999 0.999 0.    0.    0.001] \n",
      "\n",
      "\n",
      "0.504516826923077 \n",
      "\n",
      "\n",
      "0      1.0\n",
      "1      0.0\n",
      "2      0.0\n",
      "3      0.0\n",
      "4      0.0\n",
      "      ... \n",
      "411    0.0\n",
      "412    0.0\n",
      "413    1.0\n",
      "414    1.0\n",
      "415    1.0\n",
      "Name: related_prob, Length: 416, dtype: float64 \n",
      "\n",
      "\n",
      "0      1.000\n",
      "1      0.999\n",
      "2      0.999\n",
      "3      1.000\n",
      "4      0.999\n",
      "       ...  \n",
      "411    1.000\n",
      "412    0.999\n",
      "413    1.000\n",
      "414    0.999\n",
      "415    0.998\n",
      "Name: pred_prob, Length: 416, dtype: float64 \n",
      "\n",
      "\n",
      "0      0.000\n",
      "1      0.999\n",
      "2      0.999\n",
      "3      1.000\n",
      "4      0.999\n",
      "       ...  \n",
      "411    1.000\n",
      "412    0.999\n",
      "413    0.000\n",
      "414    0.001\n",
      "415    0.002\n",
      "Length: 416, dtype: float64 \n",
      "\n",
      "\n",
      "[0.    0.999 0.999 1.    0.999 0.001 1.    0.001 0.    0.999 0.999 0.\n",
      " 0.001 1.    0.    0.    0.    0.001 0.    0.    0.999 1.    1.    0.\n",
      " 0.    1.    0.    1.    1.    0.998 0.    0.    1.    0.001 0.    0.998\n",
      " 0.001 1.    1.    0.999 1.    0.999 0.004 1.    1.    0.    0.    0.\n",
      " 0.996 0.996 0.    0.999 0.    0.    0.983 1.    1.    0.996 0.001 0.001\n",
      " 0.999 0.001 0.999 0.001 0.001 0.001 1.    1.    0.007 0.    1.    0.\n",
      " 0.995 1.    0.    1.    0.988 0.998 0.001 0.    0.    1.    1.    1.\n",
      " 0.014 0.001 0.999 0.001 1.    0.001 0.    1.    0.002 0.    0.001 1.\n",
      " 0.999 0.    1.    0.    0.    1.    1.    0.    1.    0.    0.999 0.999\n",
      " 1.    1.    0.001 1.    1.    0.001 1.    0.    1.    0.004 1.    0.\n",
      " 0.    1.    0.    0.988 0.001 0.001 0.    0.    0.999 0.    0.    0.\n",
      " 0.984 0.    0.999 0.997 1.    0.    0.    0.003 0.    0.    1.    0.941\n",
      " 1.    0.    0.985 0.998 0.    1.    1.    0.999 0.    0.998 0.999 0.998\n",
      " 0.006 0.002 1.    0.999 1.    1.    1.    0.999 0.    0.997 0.    0.998\n",
      " 0.    0.001 0.003 0.001 0.001 1.    0.994 0.001 0.    0.999 0.002 0.\n",
      " 1.    1.    0.    0.001 0.006 1.    1.    0.    0.002 1.    1.    1.\n",
      " 0.    0.    0.999 1.    1.    0.    1.    0.999 0.001 0.001 0.    0.\n",
      " 0.001 1.    0.    0.001 0.002 1.    0.    1.    0.    1.    0.001 0.\n",
      " 1.    1.    0.001 1.    0.    1.    0.    1.    0.999 0.    0.    0.001\n",
      " 0.999 0.999 0.    1.    0.009 0.    1.    0.    0.    0.    0.982 1.\n",
      " 0.    0.    0.    0.    0.999 1.    0.    0.988 1.    0.999 1.    1.\n",
      " 0.999 0.001 0.999 0.003 0.    0.986 1.    0.997 0.002 0.002 1.    0.\n",
      " 0.    0.    0.999 1.    0.998 1.    0.001 1.    0.004 1.    0.    0.228\n",
      " 0.    0.001 1.    0.    1.    0.003 0.001 0.    0.001 1.    0.999 0.\n",
      " 0.    0.999 1.    0.998 0.    0.    0.003 0.    1.    1.    1.    0.009\n",
      " 1.    1.    1.    1.    0.001 0.997 0.    1.    1.    0.999 0.    0.\n",
      " 1.    1.    1.    1.    0.    0.001 0.158 0.999 0.889 0.998 1.    0.999\n",
      " 0.    0.    0.997 1.    1.    0.    1.    0.    0.119 0.001 1.    0.995\n",
      " 0.032 0.    0.    0.004 0.999 0.    0.007 0.    0.999 1.    1.    1.\n",
      " 0.    0.    1.    0.    0.    1.    1.    1.    0.    0.938 0.    0.003\n",
      " 0.001 0.999 0.001 0.    0.985 1.    1.    0.002 0.001 0.001 0.014 1.\n",
      " 1.    0.    0.    0.    1.    0.104 0.    0.001 1.    0.001 0.001 0.001\n",
      " 0.    1.    0.999 1.    0.015 0.006 1.    0.999 0.995 0.997 0.    0.\n",
      " 0.    0.998 1.    1.    1.    0.508 1.    0.001 0.999 0.    1.    0.999\n",
      " 1.    0.989 0.    1.    0.999 0.    0.001 0.002] \n",
      "\n",
      "\n",
      "0.5020504807692308 \n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>llm_name</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f1</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>support</th>\n",
       "      <th>calibration_error</th>\n",
       "      <th>edge_value</th>\n",
       "      <th>effect_type</th>\n",
       "      <th>finetuned</th>\n",
       "      <th>parse_style</th>\n",
       "      <th>prompt_style</th>\n",
       "      <th>uc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>upstage/llama-30b-instruct-2048</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>[0.7668161434977578]</td>\n",
       "      <td>[0.7154811715481172]</td>\n",
       "      <td>[0.8260869565217391]</td>\n",
       "      <td>[207]</td>\n",
       "      <td>0.502404</td>\n",
       "      <td>binary_weight</td>\n",
       "      <td>directly</td>\n",
       "      <td>False</td>\n",
       "      <td>rules</td>\n",
       "      <td>yes_no</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>upstage/llama-30b-instruct-2048</td>\n",
       "      <td>0.721154</td>\n",
       "      <td>[0.7025641025641026]</td>\n",
       "      <td>[0.7486338797814208]</td>\n",
       "      <td>[0.6618357487922706]</td>\n",
       "      <td>[207]</td>\n",
       "      <td>0.552457</td>\n",
       "      <td>distribution</td>\n",
       "      <td>directly</td>\n",
       "      <td>False</td>\n",
       "      <td>categories_perplexity</td>\n",
       "      <td>categorise</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>upstage/llama-30b-instruct-2048</td>\n",
       "      <td>0.721154</td>\n",
       "      <td>[0.6979166666666666]</td>\n",
       "      <td>[0.7570621468926554]</td>\n",
       "      <td>[0.6473429951690821]</td>\n",
       "      <td>[207]</td>\n",
       "      <td>0.550707</td>\n",
       "      <td>distribution</td>\n",
       "      <td>directly</td>\n",
       "      <td>False</td>\n",
       "      <td>categories_perplexity</td>\n",
       "      <td>categorise</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>upstage/llama-30b-instruct-2048</td>\n",
       "      <td>0.742788</td>\n",
       "      <td>[0.7784679089026917]</td>\n",
       "      <td>[0.6811594202898551]</td>\n",
       "      <td>[0.9082125603864735]</td>\n",
       "      <td>[207]</td>\n",
       "      <td>0.502404</td>\n",
       "      <td>binary_weight</td>\n",
       "      <td>directly</td>\n",
       "      <td>False</td>\n",
       "      <td>categories_rules</td>\n",
       "      <td>open</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>upstage/llama-30b-instruct-2048</td>\n",
       "      <td>0.709135</td>\n",
       "      <td>[0.7603960396039603]</td>\n",
       "      <td>[0.6442953020134228]</td>\n",
       "      <td>[0.927536231884058]</td>\n",
       "      <td>[207]</td>\n",
       "      <td>0.504517</td>\n",
       "      <td>distribution</td>\n",
       "      <td>directly</td>\n",
       "      <td>False</td>\n",
       "      <td>categories_perplexity</td>\n",
       "      <td>cot_categorise</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>upstage/llama-30b-instruct-2048</td>\n",
       "      <td>0.701923</td>\n",
       "      <td>[0.752]</td>\n",
       "      <td>[0.6416382252559727]</td>\n",
       "      <td>[0.9082125603864735]</td>\n",
       "      <td>[207]</td>\n",
       "      <td>0.502050</td>\n",
       "      <td>distribution</td>\n",
       "      <td>directly</td>\n",
       "      <td>False</td>\n",
       "      <td>categories_perplexity</td>\n",
       "      <td>cot_categorise</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          llm_name  accuracy                    f1  \\\n",
       "0  upstage/llama-30b-instruct-2048  0.750000  [0.7668161434977578]   \n",
       "1  upstage/llama-30b-instruct-2048  0.721154  [0.7025641025641026]   \n",
       "2  upstage/llama-30b-instruct-2048  0.721154  [0.6979166666666666]   \n",
       "3  upstage/llama-30b-instruct-2048  0.742788  [0.7784679089026917]   \n",
       "4  upstage/llama-30b-instruct-2048  0.709135  [0.7603960396039603]   \n",
       "5  upstage/llama-30b-instruct-2048  0.701923               [0.752]   \n",
       "\n",
       "              precision                recall support  calibration_error  \\\n",
       "0  [0.7154811715481172]  [0.8260869565217391]   [207]           0.502404   \n",
       "1  [0.7486338797814208]  [0.6618357487922706]   [207]           0.552457   \n",
       "2  [0.7570621468926554]  [0.6473429951690821]   [207]           0.550707   \n",
       "3  [0.6811594202898551]  [0.9082125603864735]   [207]           0.502404   \n",
       "4  [0.6442953020134228]   [0.927536231884058]   [207]           0.504517   \n",
       "5  [0.6416382252559727]  [0.9082125603864735]   [207]           0.502050   \n",
       "\n",
       "      edge_value effect_type  finetuned            parse_style  \\\n",
       "0  binary_weight    directly      False                  rules   \n",
       "1   distribution    directly      False  categories_perplexity   \n",
       "2   distribution    directly      False  categories_perplexity   \n",
       "3  binary_weight    directly      False       categories_rules   \n",
       "4   distribution    directly      False  categories_perplexity   \n",
       "5   distribution    directly      False  categories_perplexity   \n",
       "\n",
       "     prompt_style     uc  \n",
       "0          yes_no  False  \n",
       "1      categorise   True  \n",
       "2      categorise  False  \n",
       "3            open  False  \n",
       "4  cot_categorise   True  \n",
       "5  cot_categorise  False  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "li_exps_filt1 = filter_exp(li_all_experiments, effect_type=['directly'], llm_names=['7b'])\n",
    "li_exps_filt1_w_res = calc_eval_metrics(li_exps_filt1, metrics=['accuracy','precision','recall','f1','calibration_error'] )\n",
    "df_exps_filt1 = convert_li_exp_to_df(li_exps_filt1_w_res)\n",
    "display(df_exps_filt1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) [Probabilistic predictions]: AUC-ROC, Brier Score (of non-finetuned and finetuned models with varied parse_style_prompt_style but effect_type fixed to 'indirectly' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0      1.0\n",
      "1      0.0\n",
      "2      0.0\n",
      "3      0.0\n",
      "4      0.0\n",
      "      ... \n",
      "411    0.0\n",
      "412    0.0\n",
      "413    1.0\n",
      "414    1.0\n",
      "415    1.0\n",
      "Name: related_prob, Length: 416, dtype: float64 \n",
      "\n",
      "\n",
      "0      0.721\n",
      "1      0.911\n",
      "2      0.886\n",
      "3      0.973\n",
      "4      0.996\n",
      "       ...  \n",
      "411    0.985\n",
      "412    0.936\n",
      "413    0.529\n",
      "414    0.828\n",
      "415    0.624\n",
      "Name: pred_prob, Length: 416, dtype: float64 \n",
      "\n",
      "\n",
      "0      0.279\n",
      "1      0.911\n",
      "2      0.886\n",
      "3      0.973\n",
      "4      0.996\n",
      "       ...  \n",
      "411    0.985\n",
      "412    0.936\n",
      "413    0.471\n",
      "414    0.172\n",
      "415    0.376\n",
      "Length: 416, dtype: float64 \n",
      "\n",
      "\n",
      "[0.279 0.911 0.886 0.973 0.996 0.048 0.974 0.256 0.226 0.83  0.775 0.146\n",
      " 0.185 0.966 0.187 0.277 0.117 0.444 0.047 0.201 0.568 0.806 0.988 0.16\n",
      " 0.449 0.989 0.187 0.988 0.967 0.643 0.295 0.263 0.988 0.383 0.5   0.973\n",
      " 0.118 0.984 0.982 0.546 0.946 0.911 0.127 0.978 0.504 0.255 0.283 0.225\n",
      " 0.92  0.763 0.479 0.842 0.055 0.156 0.513 0.607 0.989 0.962 0.225 0.358\n",
      " 0.665 0.158 0.968 0.309 0.309 0.486 0.982 0.962 0.399 0.05  0.989 0.278\n",
      " 0.959 0.997 0.323 0.722 0.909 0.74  0.134 0.189 0.36  0.974 0.971 0.98\n",
      " 0.198 0.208 0.642 0.218 0.918 0.124 0.433 0.993 0.283 0.186 0.178 0.893\n",
      " 0.953 0.143 0.581 0.375 0.176 0.799 0.984 0.236 0.983 0.302 0.99  0.74\n",
      " 0.911 0.804 0.283 0.895 0.581 0.378 0.707 0.063 0.942 0.147 0.861 0.175\n",
      " 0.055 0.9   0.223 0.802 0.492 0.298 0.152 0.194 0.89  0.247 0.398 0.191\n",
      " 0.862 0.281 0.866 0.938 0.648 0.428 0.352 0.163 0.19  0.333 0.983 0.985\n",
      " 0.953 0.175 0.847 0.681 0.165 0.65  0.809 0.74  0.149 0.961 0.525 0.868\n",
      " 0.356 0.343 0.955 0.549 0.979 0.992 0.995 0.633 0.209 0.837 0.22  0.636\n",
      " 0.081 0.02  0.436 0.178 0.172 0.965 0.937 0.094 0.338 0.66  0.194 0.436\n",
      " 0.849 0.98  0.029 0.26  0.222 0.909 0.957 0.397 0.459 0.991 0.528 0.78\n",
      " 0.334 0.225 0.699 0.751 0.639 0.362 0.94  0.669 0.151 0.485 0.276 0.145\n",
      " 0.352 0.909 0.32  0.093 0.45  0.949 0.204 0.932 0.457 0.967 0.09  0.352\n",
      " 0.987 0.907 0.285 0.969 0.029 0.562 0.27  0.994 0.596 0.168 0.333 0.354\n",
      " 0.676 0.956 0.082 0.99  0.062 0.205 0.952 0.363 0.195 0.309 0.948 0.828\n",
      " 0.063 0.324 0.46  0.268 0.532 0.993 0.132 0.812 0.991 0.94  0.686 0.972\n",
      " 0.82  0.353 0.967 0.365 0.176 0.724 0.556 0.952 0.33  0.414 0.825 0.134\n",
      " 0.247 0.338 0.881 0.978 0.995 0.7   0.114 0.991 0.028 0.93  0.384 0.356\n",
      " 0.268 0.455 0.983 0.108 0.963 0.234 0.2   0.29  0.261 0.975 0.763 0.133\n",
      " 0.067 0.644 0.985 0.809 0.188 0.1   0.386 0.44  0.997 0.99  0.987 0.081\n",
      " 0.993 0.986 0.681 0.995 0.427 0.666 0.104 0.968 0.938 0.94  0.163 0.122\n",
      " 0.976 0.985 0.73  0.993 0.254 0.009 0.128 0.801 0.958 0.579 0.84  0.943\n",
      " 0.42  0.448 0.85  0.594 0.857 0.207 0.731 0.275 0.34  0.322 0.961 0.949\n",
      " 0.232 0.284 0.254 0.273 0.911 0.198 0.149 0.263 0.738 0.617 0.634 0.611\n",
      " 0.093 0.408 0.857 0.22  0.112 0.919 0.788 0.846 0.382 0.807 0.234 0.387\n",
      " 0.103 0.878 0.411 0.079 0.705 0.966 0.96  0.191 0.267 0.145 0.337 0.744\n",
      " 0.664 0.123 0.258 0.37  0.989 0.281 0.2   0.279 0.87  0.073 0.337 0.494\n",
      " 0.221 0.997 0.596 0.977 0.077 0.12  0.981 0.523 0.741 0.97  0.374 0.169\n",
      " 0.025 0.943 0.86  0.991 0.625 0.866 0.975 0.18  0.796 0.349 0.995 0.829\n",
      " 0.943 0.962 0.249 0.985 0.936 0.471 0.172 0.376] \n",
      "\n",
      "\n",
      "0.5524567307692307 \n",
      "\n",
      "\n",
      "0      1.0\n",
      "1      0.0\n",
      "2      0.0\n",
      "3      0.0\n",
      "4      0.0\n",
      "      ... \n",
      "411    0.0\n",
      "412    0.0\n",
      "413    1.0\n",
      "414    1.0\n",
      "415    1.0\n",
      "Name: related_prob, Length: 416, dtype: float64 \n",
      "\n",
      "\n",
      "0      0.746\n",
      "1      0.975\n",
      "2      0.956\n",
      "3      0.996\n",
      "4      0.999\n",
      "       ...  \n",
      "411    0.997\n",
      "412    0.980\n",
      "413    0.585\n",
      "414    0.835\n",
      "415    0.630\n",
      "Name: pred_prob, Length: 416, dtype: float64 \n",
      "\n",
      "\n",
      "0      0.254\n",
      "1      0.975\n",
      "2      0.956\n",
      "3      0.996\n",
      "4      0.999\n",
      "       ...  \n",
      "411    0.997\n",
      "412    0.980\n",
      "413    0.415\n",
      "414    0.165\n",
      "415    0.370\n",
      "Length: 416, dtype: float64 \n",
      "\n",
      "\n",
      "[0.254 0.975 0.956 0.996 0.999 0.013 0.998 0.215 0.209 0.877 0.854 0.062\n",
      " 0.162 0.996 0.076 0.272 0.057 0.4   0.023 0.129 0.539 0.844 0.998 0.11\n",
      " 0.43  0.996 0.129 0.997 0.988 0.608 0.272 0.228 0.996 0.328 0.419 0.994\n",
      " 0.056 0.995 0.995 0.626 0.983 0.987 0.052 0.997 0.527 0.209 0.231 0.242\n",
      " 0.989 0.867 0.438 0.91  0.017 0.093 0.589 0.63  0.997 0.991 0.146 0.363\n",
      " 0.672 0.095 0.994 0.288 0.251 0.469 0.998 0.972 0.453 0.008 0.998 0.182\n",
      " 0.983 0.999 0.304 0.818 0.965 0.74  0.064 0.108 0.317 0.994 0.993 0.995\n",
      " 0.176 0.209 0.706 0.167 0.962 0.057 0.484 0.998 0.297 0.212 0.116 0.948\n",
      " 0.982 0.089 0.566 0.426 0.107 0.874 0.997 0.215 0.997 0.331 0.998 0.824\n",
      " 0.973 0.877 0.281 0.955 0.604 0.438 0.719 0.01  0.988 0.044 0.945 0.124\n",
      " 0.009 0.955 0.158 0.801 0.457 0.281 0.093 0.119 0.935 0.11  0.392 0.075\n",
      " 0.93  0.248 0.953 0.973 0.637 0.321 0.363 0.108 0.123 0.345 0.997 0.995\n",
      " 0.99  0.07  0.881 0.766 0.116 0.651 0.876 0.824 0.091 0.988 0.516 0.93\n",
      " 0.352 0.349 0.985 0.539 0.997 0.997 0.998 0.669 0.16  0.892 0.156 0.737\n",
      " 0.025 0.006 0.449 0.126 0.113 0.99  0.98  0.053 0.294 0.715 0.128 0.484\n",
      " 0.926 0.995 0.008 0.275 0.167 0.975 0.981 0.43  0.488 0.997 0.622 0.844\n",
      " 0.301 0.171 0.709 0.806 0.651 0.442 0.971 0.658 0.083 0.442 0.245 0.084\n",
      " 0.307 0.957 0.288 0.047 0.404 0.986 0.16  0.973 0.457 0.988 0.047 0.301\n",
      " 0.997 0.988 0.217 0.99  0.011 0.577 0.239 0.998 0.554 0.121 0.251 0.278\n",
      " 0.719 0.989 0.038 0.997 0.018 0.171 0.99  0.356 0.144 0.234 0.976 0.872\n",
      " 0.016 0.338 0.48  0.285 0.543 0.998 0.113 0.917 0.998 0.985 0.734 0.992\n",
      " 0.931 0.328 0.993 0.311 0.119 0.801 0.52  0.981 0.223 0.331 0.92  0.079\n",
      " 0.182 0.294 0.943 0.998 0.999 0.788 0.044 0.998 0.009 0.977 0.291 0.297\n",
      " 0.281 0.426 0.997 0.052 0.997 0.088 0.135 0.239 0.228 0.996 0.775 0.061\n",
      " 0.038 0.665 0.996 0.916 0.14  0.045 0.345 0.492 0.999 0.998 0.996 0.027\n",
      " 0.998 0.996 0.679 0.998 0.328 0.743 0.045 0.996 0.981 0.981 0.086 0.062\n",
      " 0.995 0.992 0.703 0.997 0.257 0.005 0.049 0.85  0.988 0.669 0.964 0.967\n",
      " 0.363 0.43  0.94  0.676 0.962 0.18  0.749 0.26  0.342 0.359 0.993 0.982\n",
      " 0.192 0.182 0.207 0.228 0.97  0.129 0.082 0.285 0.824 0.676 0.703 0.626\n",
      " 0.055 0.301 0.912 0.18  0.045 0.975 0.854 0.959 0.345 0.85  0.165 0.423\n",
      " 0.045 0.953 0.342 0.028 0.737 0.991 0.987 0.084 0.234 0.113 0.301 0.833\n",
      " 0.725 0.071 0.215 0.356 0.995 0.22  0.154 0.212 0.943 0.04  0.314 0.461\n",
      " 0.231 0.999 0.554 0.995 0.027 0.048 0.996 0.554 0.81  0.993 0.356 0.104\n",
      " 0.009 0.987 0.914 0.996 0.693 0.951 0.998 0.118 0.879 0.275 0.996 0.858\n",
      " 0.993 0.987 0.204 0.997 0.98  0.415 0.165 0.37 ] \n",
      "\n",
      "\n",
      "0.5507067307692307 \n",
      "\n",
      "\n",
      "0      1.0\n",
      "1      0.0\n",
      "2      0.0\n",
      "3      0.0\n",
      "4      0.0\n",
      "      ... \n",
      "411    0.0\n",
      "412    0.0\n",
      "413    1.0\n",
      "414    1.0\n",
      "415    1.0\n",
      "Name: related_prob, Length: 416, dtype: float64 \n",
      "\n",
      "\n",
      "0      1.000\n",
      "1      0.997\n",
      "2      1.000\n",
      "3      0.998\n",
      "4      0.950\n",
      "       ...  \n",
      "411    0.999\n",
      "412    0.999\n",
      "413    1.000\n",
      "414    1.000\n",
      "415    0.999\n",
      "Name: pred_prob, Length: 416, dtype: float64 \n",
      "\n",
      "\n",
      "0      0.000\n",
      "1      0.997\n",
      "2      1.000\n",
      "3      0.998\n",
      "4      0.950\n",
      "       ...  \n",
      "411    0.999\n",
      "412    0.999\n",
      "413    0.000\n",
      "414    0.000\n",
      "415    0.001\n",
      "Length: 416, dtype: float64 \n",
      "\n",
      "\n",
      "[0.    0.997 1.    0.998 0.95  0.006 1.    0.    0.    0.653 0.999 0.\n",
      " 0.    0.98  0.    0.    0.    0.    0.006 0.    0.999 1.    0.998 0.\n",
      " 0.    0.989 0.    0.997 0.999 0.999 0.    0.    0.998 0.001 0.    0.966\n",
      " 0.    0.998 0.99  0.999 0.999 0.999 0.002 1.    1.    0.    0.    0.\n",
      " 0.998 0.998 0.    1.    0.043 0.    0.992 1.    0.994 0.998 0.001 0.\n",
      " 0.999 0.    0.999 0.    0.001 0.001 1.    1.    0.499 0.    0.999 0.\n",
      " 0.977 0.999 0.    1.    0.994 0.999 0.    0.    0.    0.998 0.999 0.997\n",
      " 0.007 0.001 0.999 0.001 1.    0.001 0.    0.993 0.001 0.    0.    0.991\n",
      " 0.998 0.    1.    0.    0.    0.994 0.999 0.    0.98  0.    0.769 0.999\n",
      " 0.994 1.    0.001 1.    1.    0.    1.    0.    0.994 0.002 1.    0.\n",
      " 0.    0.998 0.    0.994 0.    0.001 0.    0.    1.    0.    0.    0.\n",
      " 0.992 0.    0.999 0.999 1.    0.    0.    0.002 0.    0.    0.996 0.961\n",
      " 0.998 0.    0.992 0.999 0.    1.    1.    0.999 0.003 0.998 1.    0.981\n",
      " 0.003 0.001 0.996 1.    1.    0.999 0.979 1.    0.    0.998 0.    0.999\n",
      " 0.    0.01  0.003 0.    0.    0.996 0.996 0.001 0.    0.999 0.001 0.\n",
      " 0.977 1.    0.147 0.001 0.004 0.983 0.996 0.    0.001 0.998 1.    1.\n",
      " 0.    0.    1.    1.    1.    0.    0.99  0.999 0.001 0.001 0.    0.\n",
      " 0.    0.996 0.    0.001 0.002 1.    0.    1.    0.    0.999 0.001 0.\n",
      " 0.997 0.991 0.    0.999 0.001 1.    0.    0.995 1.    0.    0.    0.\n",
      " 0.999 0.999 0.    0.998 0.005 0.    1.    0.    0.    0.    0.99  1.\n",
      " 0.005 0.    0.    0.    0.975 1.    0.    0.994 0.997 0.994 1.    0.999\n",
      " 0.989 0.001 0.916 0.002 0.    0.993 1.    0.998 0.001 0.001 0.982 0.\n",
      " 0.    0.    0.991 0.985 0.989 1.    0.    0.997 0.335 0.998 0.    0.12\n",
      " 0.    0.001 0.966 0.    1.    0.001 0.    0.    0.001 0.997 0.999 0.\n",
      " 0.    0.999 0.987 0.999 0.    0.    0.002 0.    0.999 0.997 0.999 0.005\n",
      " 1.    0.996 1.    1.    0.001 0.999 0.    0.983 0.995 0.999 0.    0.\n",
      " 0.997 0.93  1.    1.    0.    0.004 0.422 1.    0.943 0.999 1.    0.637\n",
      " 0.    0.    0.987 1.    0.993 0.    1.    0.    0.442 0.001 0.998 0.997\n",
      " 0.016 0.    0.    0.002 0.975 0.    0.48  0.    0.999 1.    1.    1.\n",
      " 0.    0.    1.    0.    0.    1.    1.    1.    0.    0.969 0.    0.001\n",
      " 0.001 1.    0.001 0.001 0.992 1.    0.999 0.001 0.001 0.001 0.007 1.\n",
      " 1.    0.    0.    0.    1.    0.448 0.    0.    1.    0.069 0.    0.\n",
      " 0.    1.    1.    0.998 0.007 0.003 1.    1.    0.997 0.998 0.    0.\n",
      " 0.001 0.999 1.    1.    1.    0.707 1.    0.    1.    0.    0.999 1.\n",
      " 0.982 0.994 0.    0.999 0.999 0.    0.    0.001] \n",
      "\n",
      "\n",
      "0.504516826923077 \n",
      "\n",
      "\n",
      "0      1.0\n",
      "1      0.0\n",
      "2      0.0\n",
      "3      0.0\n",
      "4      0.0\n",
      "      ... \n",
      "411    0.0\n",
      "412    0.0\n",
      "413    1.0\n",
      "414    1.0\n",
      "415    1.0\n",
      "Name: related_prob, Length: 416, dtype: float64 \n",
      "\n",
      "\n",
      "0      1.000\n",
      "1      0.999\n",
      "2      0.999\n",
      "3      1.000\n",
      "4      0.999\n",
      "       ...  \n",
      "411    1.000\n",
      "412    0.999\n",
      "413    1.000\n",
      "414    0.999\n",
      "415    0.998\n",
      "Name: pred_prob, Length: 416, dtype: float64 \n",
      "\n",
      "\n",
      "0      0.000\n",
      "1      0.999\n",
      "2      0.999\n",
      "3      1.000\n",
      "4      0.999\n",
      "       ...  \n",
      "411    1.000\n",
      "412    0.999\n",
      "413    0.000\n",
      "414    0.001\n",
      "415    0.002\n",
      "Length: 416, dtype: float64 \n",
      "\n",
      "\n",
      "[0.    0.999 0.999 1.    0.999 0.001 1.    0.001 0.    0.999 0.999 0.\n",
      " 0.001 1.    0.    0.    0.    0.001 0.    0.    0.999 1.    1.    0.\n",
      " 0.    1.    0.    1.    1.    0.998 0.    0.    1.    0.001 0.    0.998\n",
      " 0.001 1.    1.    0.999 1.    0.999 0.004 1.    1.    0.    0.    0.\n",
      " 0.996 0.996 0.    0.999 0.    0.    0.983 1.    1.    0.996 0.001 0.001\n",
      " 0.999 0.001 0.999 0.001 0.001 0.001 1.    1.    0.007 0.    1.    0.\n",
      " 0.995 1.    0.    1.    0.988 0.998 0.001 0.    0.    1.    1.    1.\n",
      " 0.014 0.001 0.999 0.001 1.    0.001 0.    1.    0.002 0.    0.001 1.\n",
      " 0.999 0.    1.    0.    0.    1.    1.    0.    1.    0.    0.999 0.999\n",
      " 1.    1.    0.001 1.    1.    0.001 1.    0.    1.    0.004 1.    0.\n",
      " 0.    1.    0.    0.988 0.001 0.001 0.    0.    0.999 0.    0.    0.\n",
      " 0.984 0.    0.999 0.997 1.    0.    0.    0.003 0.    0.    1.    0.941\n",
      " 1.    0.    0.985 0.998 0.    1.    1.    0.999 0.    0.998 0.999 0.998\n",
      " 0.006 0.002 1.    0.999 1.    1.    1.    0.999 0.    0.997 0.    0.998\n",
      " 0.    0.001 0.003 0.001 0.001 1.    0.994 0.001 0.    0.999 0.002 0.\n",
      " 1.    1.    0.    0.001 0.006 1.    1.    0.    0.002 1.    1.    1.\n",
      " 0.    0.    0.999 1.    1.    0.    1.    0.999 0.001 0.001 0.    0.\n",
      " 0.001 1.    0.    0.001 0.002 1.    0.    1.    0.    1.    0.001 0.\n",
      " 1.    1.    0.001 1.    0.    1.    0.    1.    0.999 0.    0.    0.001\n",
      " 0.999 0.999 0.    1.    0.009 0.    1.    0.    0.    0.    0.982 1.\n",
      " 0.    0.    0.    0.    0.999 1.    0.    0.988 1.    0.999 1.    1.\n",
      " 0.999 0.001 0.999 0.003 0.    0.986 1.    0.997 0.002 0.002 1.    0.\n",
      " 0.    0.    0.999 1.    0.998 1.    0.001 1.    0.004 1.    0.    0.228\n",
      " 0.    0.001 1.    0.    1.    0.003 0.001 0.    0.001 1.    0.999 0.\n",
      " 0.    0.999 1.    0.998 0.    0.    0.003 0.    1.    1.    1.    0.009\n",
      " 1.    1.    1.    1.    0.001 0.997 0.    1.    1.    0.999 0.    0.\n",
      " 1.    1.    1.    1.    0.    0.001 0.158 0.999 0.889 0.998 1.    0.999\n",
      " 0.    0.    0.997 1.    1.    0.    1.    0.    0.119 0.001 1.    0.995\n",
      " 0.032 0.    0.    0.004 0.999 0.    0.007 0.    0.999 1.    1.    1.\n",
      " 0.    0.    1.    0.    0.    1.    1.    1.    0.    0.938 0.    0.003\n",
      " 0.001 0.999 0.001 0.    0.985 1.    1.    0.002 0.001 0.001 0.014 1.\n",
      " 1.    0.    0.    0.    1.    0.104 0.    0.001 1.    0.001 0.001 0.001\n",
      " 0.    1.    0.999 1.    0.015 0.006 1.    0.999 0.995 0.997 0.    0.\n",
      " 0.    0.998 1.    1.    1.    0.508 1.    0.001 0.999 0.    1.    0.999\n",
      " 1.    0.989 0.    1.    0.999 0.    0.001 0.002] \n",
      "\n",
      "\n",
      "0.5020504807692308 \n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>llm_name</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f1</th>\n",
       "      <th>support</th>\n",
       "      <th>auc_roc</th>\n",
       "      <th>brier_score</th>\n",
       "      <th>calibration_error</th>\n",
       "      <th>edge_value</th>\n",
       "      <th>effect_type</th>\n",
       "      <th>finetuned</th>\n",
       "      <th>parse_style</th>\n",
       "      <th>prompt_style</th>\n",
       "      <th>uc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>upstage/llama-30b-instruct-2048</td>\n",
       "      <td>0.721154</td>\n",
       "      <td>[0.7025641025641026]</td>\n",
       "      <td>[207]</td>\n",
       "      <td>0.273270</td>\n",
       "      <td>0.415431</td>\n",
       "      <td>0.552457</td>\n",
       "      <td>distribution</td>\n",
       "      <td>directly</td>\n",
       "      <td>False</td>\n",
       "      <td>categories_perplexity</td>\n",
       "      <td>categorise</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>upstage/llama-30b-instruct-2048</td>\n",
       "      <td>0.721154</td>\n",
       "      <td>[0.6979166666666666]</td>\n",
       "      <td>[207]</td>\n",
       "      <td>0.262141</td>\n",
       "      <td>0.439655</td>\n",
       "      <td>0.550707</td>\n",
       "      <td>distribution</td>\n",
       "      <td>directly</td>\n",
       "      <td>False</td>\n",
       "      <td>categories_perplexity</td>\n",
       "      <td>categorise</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>upstage/llama-30b-instruct-2048</td>\n",
       "      <td>0.709135</td>\n",
       "      <td>[0.7603960396039603]</td>\n",
       "      <td>[207]</td>\n",
       "      <td>0.674398</td>\n",
       "      <td>0.495406</td>\n",
       "      <td>0.504517</td>\n",
       "      <td>distribution</td>\n",
       "      <td>directly</td>\n",
       "      <td>False</td>\n",
       "      <td>categories_perplexity</td>\n",
       "      <td>cot_categorise</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>upstage/llama-30b-instruct-2048</td>\n",
       "      <td>0.701923</td>\n",
       "      <td>[0.752]</td>\n",
       "      <td>[207]</td>\n",
       "      <td>0.498058</td>\n",
       "      <td>0.498558</td>\n",
       "      <td>0.502050</td>\n",
       "      <td>distribution</td>\n",
       "      <td>directly</td>\n",
       "      <td>False</td>\n",
       "      <td>categories_perplexity</td>\n",
       "      <td>cot_categorise</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          llm_name  accuracy                    f1 support  \\\n",
       "0  upstage/llama-30b-instruct-2048  0.721154  [0.7025641025641026]   [207]   \n",
       "1  upstage/llama-30b-instruct-2048  0.721154  [0.6979166666666666]   [207]   \n",
       "2  upstage/llama-30b-instruct-2048  0.709135  [0.7603960396039603]   [207]   \n",
       "3  upstage/llama-30b-instruct-2048  0.701923               [0.752]   [207]   \n",
       "\n",
       "    auc_roc  brier_score  calibration_error    edge_value effect_type  \\\n",
       "0  0.273270     0.415431           0.552457  distribution    directly   \n",
       "1  0.262141     0.439655           0.550707  distribution    directly   \n",
       "2  0.674398     0.495406           0.504517  distribution    directly   \n",
       "3  0.498058     0.498558           0.502050  distribution    directly   \n",
       "\n",
       "   finetuned            parse_style    prompt_style     uc  \n",
       "0      False  categories_perplexity      categorise   True  \n",
       "1      False  categories_perplexity      categorise  False  \n",
       "2      False  categories_perplexity  cot_categorise   True  \n",
       "3      False  categories_perplexity  cot_categorise  False  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "li_exps_filt2 = filter_exp(li_all_experiments, effect_type=['directly'], edge_value=['distribution'], llm_names=['30b'] )\n",
    "li_exps_filt2_w_res = calc_eval_metrics(li_exps_filt2, metrics=['accuracy','f1','roc_auc','brier_score', 'calibration_error'] )\n",
    "df_exps_filt2 = convert_li_exp_to_df(li_exps_filt2_w_res)\n",
    "display(df_exps_filt2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) Performance cross sectioned by the budget item category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy_Healthcare</th>\n",
       "      <th>f1_Healthcare</th>\n",
       "      <th>support_Healthcare</th>\n",
       "      <th>f1_Child Health</th>\n",
       "      <th>support_Child Health</th>\n",
       "      <th>f1_Social Care - Adults</th>\n",
       "      <th>support_Social Care - Adults</th>\n",
       "      <th>f1_Env &amp; Reg</th>\n",
       "      <th>support_Env &amp; Reg</th>\n",
       "      <th>f1_Social Care - Child</th>\n",
       "      <th>...</th>\n",
       "      <th>f1_Education services</th>\n",
       "      <th>support_Education services</th>\n",
       "      <th>f1_Public mental health</th>\n",
       "      <th>support_Public mental health</th>\n",
       "      <th>f1_Substance misuse - Drug misuse - adults &amp; Substance misuse - Alcohol misuse - adults &amp; Substance misuse - Preventing and reducing harm from drug misuse in adults &amp; Substance misuse - Preventing and reducing harm from alcohol misuse in adults &amp; Substance misuse - (drugs and alcohol) - youth services</th>\n",
       "      <th>support_Substance misuse - Drug misuse - adults &amp; Substance misuse - Alcohol misuse - adults &amp; Substance misuse - Preventing and reducing harm from drug misuse in adults &amp; Substance misuse - Preventing and reducing harm from alcohol misuse in adults &amp; Substance misuse - (drugs and alcohol) - youth services</th>\n",
       "      <th>f1_Planning and development services</th>\n",
       "      <th>support_Planning and development services</th>\n",
       "      <th>f1_Central services</th>\n",
       "      <th>support_Central services</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.7</td>\n",
       "      <td>0.812500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.850000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.901786</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.750</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.961538</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.790698</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.804924</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.595238</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.750</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.722222</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.651261</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.760870</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.227273</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.815789</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.650000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.750</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.671429</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.687500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.563158</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.709790</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.687500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.633333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.750</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.406250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.750</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.842857</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.650000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.815789</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.757143</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.781250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.722222</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.750</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.772727</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.772727</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.750</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.760870</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.750</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.760870</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.760870</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.760870</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.750</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18 rows  63 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    accuracy_Healthcare  f1_Healthcare  support_Healthcare  f1_Child Health  \\\n",
       "0                   0.7       0.812500                 NaN         0.850000   \n",
       "1                   NaN       0.790698                 NaN         0.804924   \n",
       "2                   NaN            NaN                 NaN              NaN   \n",
       "3                   NaN            NaN                 NaN              NaN   \n",
       "4                   NaN            NaN                 NaN              NaN   \n",
       "5                   NaN            NaN                 NaN              NaN   \n",
       "6                   NaN            NaN                 NaN              NaN   \n",
       "7                   NaN            NaN                 NaN              NaN   \n",
       "8                   NaN            NaN                 NaN              NaN   \n",
       "9                   NaN            NaN                 NaN              NaN   \n",
       "10                  NaN            NaN                 NaN              NaN   \n",
       "11                  NaN            NaN                 NaN              NaN   \n",
       "12                  NaN            NaN                 NaN              NaN   \n",
       "13                  NaN            NaN                 NaN              NaN   \n",
       "14                  NaN            NaN                 NaN              NaN   \n",
       "15                  NaN            NaN                 NaN              NaN   \n",
       "16                  NaN            NaN                 NaN              NaN   \n",
       "17                  NaN            NaN                 NaN              NaN   \n",
       "\n",
       "    support_Child Health  f1_Social Care - Adults  \\\n",
       "0                    NaN                 0.901786   \n",
       "1                    NaN                 0.916667   \n",
       "2                    NaN                      NaN   \n",
       "3                    NaN                      NaN   \n",
       "4                    NaN                      NaN   \n",
       "5                    NaN                      NaN   \n",
       "6                    NaN                      NaN   \n",
       "7                    NaN                      NaN   \n",
       "8                    NaN                      NaN   \n",
       "9                    NaN                      NaN   \n",
       "10                   NaN                      NaN   \n",
       "11                   NaN                      NaN   \n",
       "12                   NaN                      NaN   \n",
       "13                   NaN                      NaN   \n",
       "14                   NaN                      NaN   \n",
       "15                   NaN                      NaN   \n",
       "16                   NaN                      NaN   \n",
       "17                   NaN                      NaN   \n",
       "\n",
       "    support_Social Care - Adults  f1_Env & Reg  support_Env & Reg  \\\n",
       "0                            NaN         0.750                NaN   \n",
       "1                            NaN         0.875                NaN   \n",
       "2                            NaN           NaN                NaN   \n",
       "3                            NaN           NaN                NaN   \n",
       "4                            NaN           NaN                NaN   \n",
       "5                            NaN           NaN                NaN   \n",
       "6                            NaN           NaN                NaN   \n",
       "7                            NaN           NaN                NaN   \n",
       "8                            NaN           NaN                NaN   \n",
       "9                            NaN           NaN                NaN   \n",
       "10                           NaN           NaN                NaN   \n",
       "11                           NaN           NaN                NaN   \n",
       "12                           NaN           NaN                NaN   \n",
       "13                           NaN           NaN                NaN   \n",
       "14                           NaN           NaN                NaN   \n",
       "15                           NaN           NaN                NaN   \n",
       "16                           NaN           NaN                NaN   \n",
       "17                           NaN           NaN                NaN   \n",
       "\n",
       "    f1_Social Care - Child  ...  f1_Education services  \\\n",
       "0                 0.961538  ...                    NaN   \n",
       "1                 0.923077  ...                    NaN   \n",
       "2                      NaN  ...               0.750000   \n",
       "3                      NaN  ...               0.722222   \n",
       "4                      NaN  ...               0.760870   \n",
       "5                      NaN  ...               0.815789   \n",
       "6                      NaN  ...               0.671429   \n",
       "7                      NaN  ...               0.563158   \n",
       "8                      NaN  ...               0.687500   \n",
       "9                      NaN  ...               0.500000   \n",
       "10                     NaN  ...               0.842857   \n",
       "11                     NaN  ...               0.815789   \n",
       "12                     NaN  ...               0.781250   \n",
       "13                     NaN  ...               0.785714   \n",
       "14                     NaN  ...               0.772727   \n",
       "15                     NaN  ...               0.750000   \n",
       "16                     NaN  ...               0.760870   \n",
       "17                     NaN  ...               0.760870   \n",
       "\n",
       "    support_Education services  f1_Public mental health  \\\n",
       "0                          NaN                      NaN   \n",
       "1                          NaN                      NaN   \n",
       "2                          NaN                 0.595238   \n",
       "3                          NaN                 0.651261   \n",
       "4                          NaN                 0.227273   \n",
       "5                          NaN                 0.650000   \n",
       "6                          NaN                 0.687500   \n",
       "7                          NaN                 0.709790   \n",
       "8                          NaN                 0.633333   \n",
       "9                          NaN                 0.406250   \n",
       "10                         NaN                 0.650000   \n",
       "11                         NaN                 0.757143   \n",
       "12                         NaN                 0.722222   \n",
       "13                         NaN                 0.772727   \n",
       "14                         NaN                 0.785714   \n",
       "15                         NaN                 0.760870   \n",
       "16                         NaN                 0.750000   \n",
       "17                         NaN                 0.760870   \n",
       "\n",
       "    support_Public mental health  \\\n",
       "0                            NaN   \n",
       "1                            NaN   \n",
       "2                            NaN   \n",
       "3                            NaN   \n",
       "4                            NaN   \n",
       "5                            NaN   \n",
       "6                            NaN   \n",
       "7                            NaN   \n",
       "8                            NaN   \n",
       "9                            NaN   \n",
       "10                           NaN   \n",
       "11                           NaN   \n",
       "12                           NaN   \n",
       "13                           NaN   \n",
       "14                           NaN   \n",
       "15                           NaN   \n",
       "16                           NaN   \n",
       "17                           NaN   \n",
       "\n",
       "    f1_Substance misuse - Drug misuse - adults & Substance misuse - Alcohol misuse - adults & Substance misuse - Preventing and reducing harm from drug misuse in adults & Substance misuse - Preventing and reducing harm from alcohol misuse in adults & Substance misuse - (drugs and alcohol) - youth services  \\\n",
       "0                                                 NaN                                                                                                                                                                                                                                                                \n",
       "1                                                 NaN                                                                                                                                                                                                                                                                \n",
       "2                                               0.750                                                                                                                                                                                                                                                                \n",
       "3                                               0.875                                                                                                                                                                                                                                                                \n",
       "4                                               0.250                                                                                                                                                                                                                                                                \n",
       "5                                               0.750                                                                                                                                                                                                                                                                \n",
       "6                                               0.800                                                                                                                                                                                                                                                                \n",
       "7                                               0.875                                                                                                                                                                                                                                                                \n",
       "8                                               0.750                                                                                                                                                                                                                                                                \n",
       "9                                               0.750                                                                                                                                                                                                                                                                \n",
       "10                                              0.875                                                                                                                                                                                                                                                                \n",
       "11                                              0.875                                                                                                                                                                                                                                                                \n",
       "12                                              0.750                                                                                                                                                                                                                                                                \n",
       "13                                              0.875                                                                                                                                                                                                                                                                \n",
       "14                                              0.750                                                                                                                                                                                                                                                                \n",
       "15                                              0.750                                                                                                                                                                                                                                                                \n",
       "16                                              0.500                                                                                                                                                                                                                                                                \n",
       "17                                              0.750                                                                                                                                                                                                                                                                \n",
       "\n",
       "    support_Substance misuse - Drug misuse - adults & Substance misuse - Alcohol misuse - adults & Substance misuse - Preventing and reducing harm from drug misuse in adults & Substance misuse - Preventing and reducing harm from alcohol misuse in adults & Substance misuse - (drugs and alcohol) - youth services  \\\n",
       "0                                                 NaN                                                                                                                                                                                                                                                                     \n",
       "1                                                 NaN                                                                                                                                                                                                                                                                     \n",
       "2                                                 NaN                                                                                                                                                                                                                                                                     \n",
       "3                                                 NaN                                                                                                                                                                                                                                                                     \n",
       "4                                                 NaN                                                                                                                                                                                                                                                                     \n",
       "5                                                 NaN                                                                                                                                                                                                                                                                     \n",
       "6                                                 NaN                                                                                                                                                                                                                                                                     \n",
       "7                                                 NaN                                                                                                                                                                                                                                                                     \n",
       "8                                                 NaN                                                                                                                                                                                                                                                                     \n",
       "9                                                 NaN                                                                                                                                                                                                                                                                     \n",
       "10                                                NaN                                                                                                                                                                                                                                                                     \n",
       "11                                                NaN                                                                                                                                                                                                                                                                     \n",
       "12                                                NaN                                                                                                                                                                                                                                                                     \n",
       "13                                                NaN                                                                                                                                                                                                                                                                     \n",
       "14                                                NaN                                                                                                                                                                                                                                                                     \n",
       "15                                                NaN                                                                                                                                                                                                                                                                     \n",
       "16                                                NaN                                                                                                                                                                                                                                                                     \n",
       "17                                                NaN                                                                                                                                                                                                                                                                     \n",
       "\n",
       "    f1_Planning and development services  \\\n",
       "0                                    NaN   \n",
       "1                                    NaN   \n",
       "2                               0.875000   \n",
       "3                               0.700000   \n",
       "4                               0.800000   \n",
       "5                               0.750000   \n",
       "6                               0.800000   \n",
       "7                               1.000000   \n",
       "8                               0.875000   \n",
       "9                               0.750000   \n",
       "10                              1.000000   \n",
       "11                              0.833333   \n",
       "12                              0.800000   \n",
       "13                              0.833333   \n",
       "14                              0.700000   \n",
       "15                              0.750000   \n",
       "16                              0.800000   \n",
       "17                              0.700000   \n",
       "\n",
       "    support_Planning and development services  f1_Central services  \\\n",
       "0                                         NaN                  NaN   \n",
       "1                                         NaN                  NaN   \n",
       "2                                         NaN             0.800000   \n",
       "3                                         NaN             0.750000   \n",
       "4                                         NaN             0.800000   \n",
       "5                                         NaN             0.833333   \n",
       "6                                         NaN             0.833333   \n",
       "7                                         NaN             0.250000   \n",
       "8                                         NaN             0.800000   \n",
       "9                                         NaN             0.416667   \n",
       "10                                        NaN             0.800000   \n",
       "11                                        NaN             1.000000   \n",
       "12                                        NaN             0.800000   \n",
       "13                                        NaN             0.750000   \n",
       "14                                        NaN             0.700000   \n",
       "15                                        NaN             0.700000   \n",
       "16                                        NaN             0.800000   \n",
       "17                                        NaN             0.833333   \n",
       "\n",
       "    support_Central services  \n",
       "0                        NaN  \n",
       "1                        NaN  \n",
       "2                        NaN  \n",
       "3                        NaN  \n",
       "4                        NaN  \n",
       "5                        NaN  \n",
       "6                        NaN  \n",
       "7                        NaN  \n",
       "8                        NaN  \n",
       "9                        NaN  \n",
       "10                       NaN  \n",
       "11                       NaN  \n",
       "12                       NaN  \n",
       "13                       NaN  \n",
       "14                       NaN  \n",
       "15                       NaN  \n",
       "16                       NaN  \n",
       "17                       NaN  \n",
       "\n",
       "[18 rows x 63 columns]"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "li_exps_filt3 = filter_exp(li_all_experiments, effect_type=['directly'] )\n",
    "li_exps_filt3_w_res = calc_eval_metrics(li_exps_filt3, metrics=['accuracy','f1','auc_roc','brier_score'], breakdown_by_budgetitem=True )\n",
    "df_exps_filt3 = convert_li_exp_to_df(li_exps_filt3_w_res)\n",
    "df_exps_filt3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4) Performance cross sectioned by the budget item pre and post finetuning - In relation to dataset distribution e.g. more articles on 'health' than 'education' so we expect better performance increase on 'health' than 'education'. And the possible effects on downstream model from this e.g. are effects with more academic research better modelled. Or if there are correllated factors, we will essentially learn better studied factors more"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5) Performance change in top performing models when effect tyle is rotated between effect types"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6) Table showing Performance change w/ and w/o using -unbiase predictions flag for top models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "alanturing",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "cc50b8d0f7e8d8fb88331066a22b4d3e98f2c46ac896a3cf7dc663ff0af4e185"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
